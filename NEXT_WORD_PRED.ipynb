{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5251cbce-38c3-41b7-a361-35354118cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs= '''\n",
    "Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
    "\n",
    "This eBook is for the use of anyone anywhere at no cost and with\n",
    "almost no restrictions whatsoever.  You may copy it, give it away or\n",
    "re-use it under the terms of the Project Gutenberg License included\n",
    "with this eBook or online at www.gutenberg.net\n",
    "\n",
    "\n",
    "Title: The Adventures of Sherlock Holmes\n",
    "\n",
    "Author: Arthur Conan Doyle\n",
    "\n",
    "Release Date: November 29, 2002 [EBook #1661]\n",
    "Last Updated: May 20, 2019\n",
    "\n",
    "Language: English\n",
    "\n",
    "Character set encoding: UTF-8\n",
    "\n",
    "*** START OF THIS PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\n",
    "\n",
    "\n",
    "\n",
    "Produced by an anonymous Project Gutenberg volunteer and Jose Menendez\n",
    "\n",
    "\n",
    "\n",
    "cover\n",
    "\n",
    "\n",
    "\n",
    "The Adventures of Sherlock Holmes\n",
    "\n",
    "\n",
    "\n",
    "by Arthur Conan Doyle\n",
    "\n",
    "\n",
    "\n",
    "Contents\n",
    "\n",
    "\n",
    "   I.     A Scandal in Bohemia\n",
    "   II.    The Red-Headed League\n",
    "   III.   A Case of Identity\n",
    "   IV.    The Boscombe Valley Mystery\n",
    "   V.     The Five Orange Pips\n",
    "   VI.    The Man with the Twisted Lip\n",
    "   VII.   The Adventure of the Blue Carbuncle\n",
    "   VIII.  The Adventure of the Speckled Band\n",
    "   IX.    The Adventure of the Engineer’s Thumb\n",
    "   X.     The Adventure of the Noble Bachelor\n",
    "   XI.    The Adventure of the Beryl Coronet\n",
    "   XII.   The Adventure of the Copper Beeches\n",
    "\n",
    "\n",
    "\n",
    "I. A SCANDAL IN BOHEMIA\n",
    "\n",
    "\n",
    "I.\n",
    "\n",
    "To Sherlock Holmes she is always _the_ woman. I have seldom heard him\n",
    "mention her under any other name. In his eyes she eclipses and\n",
    "predominates the whole of her sex. It was not that he felt any emotion\n",
    "akin to love for Irene Adler. All emotions, and that one particularly,\n",
    "were abhorrent to his cold, precise but admirably balanced mind. He\n",
    "was, I take it, the most perfect reasoning and observing machine that\n",
    "the world has seen, but as a lover he would have placed himself in a\n",
    "false position. He never spoke of the softer passions, save with a gibe\n",
    "and a sneer. They were admirable things for the observer—excellent for\n",
    "drawing the veil from men’s motives and actions. But for the trained\n",
    "reasoner to admit such intrusions into his own delicate and finely\n",
    "adjusted temperament was to introduce a distracting factor which might\n",
    "throw a doubt upon all his mental results. Grit in a sensitive\n",
    "instrument, or a crack in one of his own high-power lenses, would not\n",
    "be more disturbing than a strong emotion in a nature such as his. And\n",
    "yet there was but one woman to him, and that woman was the late Irene\n",
    "Adler, of dubious and questionable memory.\n",
    "\n",
    "I had seen little of Holmes lately. My marriage had drifted us away\n",
    "from each other. My own complete happiness, and the home-centred\n",
    "interests which rise up around the man who first finds himself master\n",
    "of his own establishment, were sufficient to absorb all my attention,\n",
    "while Holmes, who loathed every form of society with his whole Bohemian\n",
    "soul, remained in our lodgings in Baker Street, buried among his old\n",
    "books, and alternating from week to week between cocaine and ambition,\n",
    "the drowsiness of the drug, and the fierce energy of his own keen\n",
    "nature. He was still, as ever, deeply attracted by the study of crime,\n",
    "and occupied his immense faculties and extraordinary powers of\n",
    "observation in following out those clues, and clearing up those\n",
    "mysteries which had been abandoned as hopeless by the official police.\n",
    "From time to time I heard some vague account of his doings: of his\n",
    "summons to Odessa in the case of the Trepoff murder, of his clearing up\n",
    "of the singular tragedy of the Atkinson brothers at Trincomalee, and\n",
    "finally of the mission which he had accomplished so delicately and\n",
    "successfully for the reigning family of Holland. Beyond these signs of\n",
    "his activity, however, which I merely shared with all the readers of\n",
    "the daily press, I knew little of my former friend and companion.\n",
    "\n",
    "One night—it was on the twentieth of March, 1888—I was returning from a\n",
    "journey to a patient (for I had now returned to civil practice), when\n",
    "my way led me through Baker Street. As I passed the well-remembered\n",
    "door, which must always be associated in my mind with my wooing, and\n",
    "with the dark incidents of the Study in Scarlet, I was seized with a\n",
    "keen desire to see Holmes again, and to know how he was employing his\n",
    "extraordinary powers. His rooms were brilliantly lit, and, even as I\n",
    "looked up, I saw his tall, spare figure pass twice in a dark silhouette\n",
    "against the blind. He was pacing the room swiftly, eagerly, with his\n",
    "head sunk upon his chest and his hands clasped behind him. To me, who\n",
    "knew his every mood and habit, his attitude and manner told their own\n",
    "story. He was at work again. He had risen out of his drug-created\n",
    "dreams and was hot upon the scent of some new problem. I rang the bell\n",
    "and was shown up to the chamber which had formerly been in part my own.\n",
    "\n",
    "His manner was not effusive. It seldom was; but he was glad, I think,\n",
    "to see me. With hardly a word spoken, but with a kindly eye, he waved\n",
    "me to an armchair, threw across his case of cigars, and indicated a\n",
    "spirit case and a gasogene in the corner. Then he stood before the fire\n",
    "and looked me over in his singular introspective fashion.\n",
    "\n",
    "“Wedlock suits you,” he remarked. “I think, Watson, that you have put\n",
    "on seven and a half pounds since I saw you.”\n",
    "\n",
    "“Seven!” I answered.\n",
    "\n",
    "“Indeed, I should have thought a little more. Just a trifle more, I\n",
    "fancy, Watson. And in practice again, I observe. You did not tell me\n",
    "that you intended to go into harness.”\n",
    "\n",
    "“Then, how do you know?”\n",
    "\n",
    "“I see it, I deduce it. How do I know that you have been getting\n",
    "yourself very wet lately, and that you have a most clumsy and careless\n",
    "servant girl?”\n",
    "\n",
    "“My dear Holmes,” said I, “this is too much. You would certainly have\n",
    "been burned, had you lived a few centuries ago. It is true that I had a\n",
    "country walk on Thursday and came home in a dreadful mess, but as I\n",
    "have changed my clothes I can’t imagine how you deduce it. As to Mary\n",
    "Jane, she is incorrigible, and my wife has given her notice, but there,\n",
    "again, I fail to see how you work it out.”\n",
    "\n",
    "He chuckled to himself and rubbed his long, nervous hands together.\n",
    "\n",
    "“It is simplicity itself,” said he; “my eyes tell me that on the inside\n",
    "of your left shoe, just where the firelight strikes it, the leather is\n",
    "scored by six almost parallel cuts. Obviously they have been caused by\n",
    "someone who has very carelessly scraped round the edges of the sole in\n",
    "order to remove crusted mud from it. Hence, you see, my double\n",
    "deduction that you had been out in vile weather, and that you had a\n",
    "particularly malignant boot-slitting specimen of the London slavey. As\n",
    "to your practice, if a gentleman walks into my rooms smelling of\n",
    "iodoform, with a black mark of nitrate of silver upon his right\n",
    "forefinger, and a bulge on the right side of his top-hat to show where\n",
    "he has secreted his stethoscope, I must be dull, indeed, if I do not\n",
    "pronounce him to be an active member of the medical profession.”\n",
    "\n",
    "I could not help laughing at the ease with which he explained his\n",
    "process of deduction. “When I hear you give your reasons,” I remarked,\n",
    "“the thing always appears to me to be so ridiculously simple that I\n",
    "could easily do it myself, though at each successive instance of your\n",
    "reasoning I am baffled until you explain your process. And yet I\n",
    "believe that my eyes are as good as yours.”\n",
    "\n",
    "“Quite so,” he answered, lighting a cigarette, and throwing himself\n",
    "down into an armchair. “You see, but you do not observe. The\n",
    "distinction is clear. For example, you have frequently seen the steps\n",
    "which lead up from the hall to this room.”\n",
    "\n",
    "“Frequently.”\n",
    "\n",
    "“How often?”\n",
    "\n",
    "“Well, some hundreds of times.”\n",
    "\n",
    "“Then how many are there?”\n",
    "\n",
    "“How many? I don’t know.”\n",
    "\n",
    "“Quite so! You have not observed. And yet you have seen. That is just\n",
    "my point. Now, I know that there are seventeen steps, because I have\n",
    "both seen and observed. By the way, since you are interested in these\n",
    "little problems, and since you are good enough to chronicle one or two\n",
    "of my trifling experiences, you may be interested in this.” He threw\n",
    "over a sheet of thick, pink-tinted notepaper which had been lying open\n",
    "upon the table. “It came by the last post,” said he. “Read it aloud.”\n",
    "\n",
    "The note was undated, and without either signature or address.\n",
    "\n",
    "“There will call upon you to-night, at a quarter to eight o’clock,” it\n",
    "said, “a gentleman who desires to consult you upon a matter of the very\n",
    "deepest moment. Your recent services to one of the royal houses of\n",
    "Europe have shown that you are one who may safely be trusted with\n",
    "matters which are of an importance which can hardly be exaggerated.\n",
    "This account of you we have from all quarters received. Be in your\n",
    "chamber then at that hour, and do not take it amiss if your visitor\n",
    "wear a mask.”\n",
    "\n",
    "“This is indeed a mystery,” I remarked. “What do you imagine that it\n",
    "means?”\n",
    "\n",
    "“I have no data yet. It is a capital mistake to theorise before one has\n",
    "data. Insensibly one begins to twist facts to suit theories, instead of\n",
    "theories to suit facts. But the note itself. What do you deduce from\n",
    "it?”\n",
    "\n",
    "I carefully examined the writing, and the paper upon which it was\n",
    "written.\n",
    "\n",
    "“The man who wrote it was presumably well to do,” I remarked,\n",
    "endeavouring to imitate my companion’s processes. “Such paper could not\n",
    "be bought under half a crown a packet. It is peculiarly strong and\n",
    "stiff.”\n",
    "\n",
    "“Peculiar—that is the very word,” said Holmes. “It is not an English\n",
    "paper at all. Hold it up to the light.”\n",
    "\n",
    "I did so, and saw a large “E” with a small “g,” a “P,” and a large “G”\n",
    "with a small “t” woven into the texture of the paper.\n",
    "\n",
    "“What do you make of that?” asked Holmes.\n",
    "\n",
    "“The name of the maker, no doubt; or his monogram, rather.”\n",
    "\n",
    "“Not at all. The ‘G’ with the small ‘t’ stands for ‘Gesellschaft,’\n",
    "which is the German for ‘Company.’ It is a customary contraction like\n",
    "our ‘Co.’ ‘P,’ of course, stands for ‘Papier.’ Now for the ‘Eg.’ Let us\n",
    "glance at our Continental Gazetteer.” He took down a heavy brown volume\n",
    "from his shelves. “Eglow, Eglonitz—here we are, Egria. It is in a\n",
    "German-speaking country—in Bohemia, not far from Carlsbad. ‘Remarkable\n",
    "as being the scene of the death of Wallenstein, and for its numerous\n",
    "glass-factories and paper-mills.’ Ha, ha, my boy, what do you make of\n",
    "that?” His eyes sparkled, and he sent up a great blue triumphant cloud\n",
    "from his cigarette.\n",
    "\n",
    "“The paper was made in Bohemia,” I said.\n",
    "\n",
    "“Precisely. And the man who wrote the note is a German. Do you note the\n",
    "peculiar construction of the sentence—‘This account of you we have from\n",
    "all quarters received.’ A Frenchman or Russian could not have written\n",
    "that. It is the German who is so uncourteous to his verbs. It only\n",
    "remains, therefore, to discover what is wanted by this German who\n",
    "writes upon Bohemian paper and prefers wearing a mask to showing his\n",
    "face. And here he comes, if I am not mistaken, to resolve all our\n",
    "doubts.”\n",
    "\n",
    "As he spoke there was the sharp sound of horses’ hoofs and grating\n",
    "wheels against the curb, followed by a sharp pull at the bell. Holmes\n",
    "whistled.\n",
    "\n",
    "“A pair, by the sound,” said he. “Yes,” he continued, glancing out of\n",
    "the window. “A nice little brougham and a pair of beauties. A hundred\n",
    "and fifty guineas apiece. There’s money in this case, Watson, if there\n",
    "is nothing else.”\n",
    "\n",
    "“I think that I had better go, Holmes.”\n",
    "\n",
    "“Not a bit, Doctor. Stay where you are. I am lost without my Boswell.\n",
    "And this promises to be interesting. It would be a pity to miss it.”\n",
    "\n",
    "“But your client—”\n",
    "\n",
    "“Never mind him. I may want your help, and so may he. Here he comes.\n",
    "Sit down in that armchair, Doctor, and give us your best attention.”\n",
    "\n",
    "A slow and heavy step, which had been heard upon the stairs and in the\n",
    "passage, paused immediately outside the door. Then there was a loud and\n",
    "authoritative tap.\n",
    "\n",
    "“Come in!” said Holmes.\n",
    "\n",
    "A man entered who could hardly have been less than six feet six inches\n",
    "in height, with the chest and limbs of a Hercules. His dress was rich\n",
    "with a richness which would, in England, be looked upon as akin to bad\n",
    "taste. Heavy bands of astrakhan were slashed across the sleeves and\n",
    "fronts of his double-breasted coat, while the deep blue cloak which was\n",
    "thrown over his shoulders was lined with flame-coloured silk and\n",
    "secured at the neck with a brooch which consisted of a single flaming\n",
    "beryl. Boots which extended halfway up his calves, and which were\n",
    "trimmed at the tops with rich brown fur, completed the impression of\n",
    "barbaric opulence which was suggested by his whole appearance. He\n",
    "carried a broad-brimmed hat in his hand, while he wore across the upper\n",
    "part of his face, extending down past the cheekbones, a black vizard\n",
    "mask, which he had apparently adjusted that very moment, for his hand\n",
    "was still raised to it as he entered. From the lower part of the face\n",
    "he appeared to be a man of strong character, with a thick, hanging lip,\n",
    "and a long, straight chin suggestive of resolution pushed to the length\n",
    "of obstinacy.\n",
    "\n",
    "“You had my note?” he asked with a deep harsh voice and a strongly\n",
    "marked German accent. “I told you that I would call.” He looked from\n",
    "one to the other of us, as if uncertain which to address.\n",
    "\n",
    "“Pray take a seat,” said Holmes. “This is my friend and colleague, Dr.\n",
    "Watson, who is occasionally good enough to help me in my cases. Whom\n",
    "have I the honour to address?”\n",
    "\n",
    "“You may address me as the Count Von Kramm, a Bohemian nobleman. I\n",
    "understand that this gentleman, your friend, is a man of honour and\n",
    "discretion, whom I may trust with a matter of the most extreme\n",
    "importance. If not, I should much prefer to communicate with you\n",
    "alone.”\n",
    "\n",
    "I rose to go, but Holmes caught me by the wrist and pushed me back into\n",
    "my chair. “It is both, or none,” said he. “You may say before this\n",
    "gentleman anything which you may say to me.”\n",
    "\n",
    "The Count shrugged his broad shoulders. “Then I must begin,” said he,\n",
    "“by binding you both to absolute secrecy for two years; at the end of\n",
    "that time the matter will be of no importance. At present it is not too\n",
    "much to say that it is of such weight it may have an influence upon\n",
    "European history.”\n",
    "\n",
    "“I promise,” said Holmes.\n",
    "\n",
    "“And I.”\n",
    "\n",
    "“You will excuse this mask,” continued our strange visitor. “The august\n",
    "person who employs me wishes his agent to be unknown to you, and I may\n",
    "confess at once that the title by which I have just called myself is\n",
    "not exactly my own.”\n",
    "\n",
    "“I was aware of it,” said Holmes dryly.\n",
    "\n",
    "“The circumstances are of great delicacy, and every precaution has to\n",
    "be taken to quench what might grow to be an immense scandal and\n",
    "seriously compromise one of the reigning families of Europe. To speak\n",
    "plainly, the matter implicates the great House of Ormstein, hereditary\n",
    "kings of Bohemia.”\n",
    "\n",
    "“I was also aware of that,” murmured Holmes, settling himself down in\n",
    "his armchair and closing his eyes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "22d78fe3-e44b-4b38-9736-a912c5024855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\abshiek raj\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2025653e-1083-426d-950b-34d0ac5cacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4cc65167-6571-44df-b02d-03bdd4b066d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8fe09589-39fc-4e1f-896d-33f1c5a8f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1adbaade-42dd-47c2-8b10-29214ac444c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "85559e2a-ba90-4937-9c74-cae9557fb0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.net\n",
      "\n",
      "\n",
      "Title: The Adventures of Sherlock Holmes\n",
      "\n",
      "Author: Arthur Conan Doyle\n",
      "\n",
      "Release Date: November 29, 2002 [EBook #1661]\n",
      "Last Updated: May 20, 2019\n",
      "\n",
      "Language: English\n",
      "\n",
      "Character set encoding: UTF-8\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK THE ADVENTURES OF SHERLOCK HOLMES ***\n",
      "\n",
      "\n",
      "\n",
      "Produced by an anonymous Project Gutenberg volunteer and Jose Menendez\n",
      "\n",
      "\n",
      "\n",
      "cover\n",
      "\n",
      "\n",
      "\n",
      "The Adventures of Sherlock Holmes\n",
      "\n",
      "\n",
      "\n",
      "by Arthur Conan Doyle\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      "\n",
      "   I.     A Scandal in Bohemia\n",
      "   II.    The Red-Headed League\n",
      "   III.   A Case of Identity\n",
      "   IV.    The Boscombe Valley Mystery\n",
      "   V.     The Five Orange Pips\n",
      "   VI.    The Man with the Twisted Lip\n",
      "   VII.   The Adventure of the Blue Carbuncle\n",
      "   VIII.  The Adventure of the Speckled Band\n",
      "   IX.    The Adventure of the Engineer’s Thumb\n",
      "   X.     The Adventure of the Noble Bachelor\n",
      "   XI.    The Adventure of the Beryl Coronet\n",
      "   XII.   The Adventure of the Copper Beeches\n",
      "\n",
      "\n",
      "\n",
      "I. A SCANDAL IN BOHEMIA\n",
      "\n",
      "\n",
      "I.\n",
      "\n",
      "To Sherlock Holmes she is always _the_ woman. I have seldom heard him\n",
      "mention her under any other name. In his eyes she eclipses and\n",
      "predominates the whole of her sex. It was not that he felt any emotion\n",
      "akin to love for Irene Adler. All emotions, and that one particularly,\n",
      "were abhorrent to his cold, precise but admirably balanced mind. He\n",
      "was, I take it, the most perfect reasoning and observing machine that\n",
      "the world has seen, but as a lover he would have placed himself in a\n",
      "false position. He never spoke of the softer passions, save with a gibe\n",
      "and a sneer. They were admirable things for the observer—excellent for\n",
      "drawing the veil from men’s motives and actions. But for the trained\n",
      "reasoner to admit such intrusions into his own delicate and finely\n",
      "adjusted temperament was to introduce a distracting factor which might\n",
      "throw a doubt upon all his mental results. Grit in a sensitive\n",
      "instrument, or a crack in one of his own high-power lenses, would not\n",
      "be more disturbing than a strong emotion in a nature such as his. And\n",
      "yet there was but one woman to him, and that woman was the late Irene\n",
      "Adler, of dubious and questionable memory.\n",
      "\n",
      "I had seen little of Holmes lately. My marriage had drifted us away\n",
      "from each other. My own complete happiness, and the home-centred\n",
      "interests which rise up around the man who first finds himself master\n",
      "of his own establishment, were sufficient to absorb all my attention,\n",
      "while Holmes, who loathed every form of society with his whole Bohemian\n",
      "soul, remained in our lodgings in Baker Street, buried among his old\n",
      "books, and alternating from week to week between cocaine and ambition,\n",
      "the drowsiness of the drug, and the fierce energy of his own keen\n",
      "nature. He was still, as ever, deeply attracted by the study of crime,\n",
      "and occupied his immense faculties and extraordinary powers of\n",
      "observation in following out those clues, and clearing up those\n",
      "mysteries which had been abandoned as hopeless by the official police.\n",
      "From time to time I heard some vague account of his doings: of his\n",
      "summons to Odessa in the case of the Trepoff murder, of his clearing up\n",
      "of the singular tragedy of the Atkinson brothers at Trincomalee, and\n",
      "finally of the mission which he had accomplished so delicately and\n",
      "successfully for the reigning family of Holland. Beyond these signs of\n",
      "his activity, however, which I merely shared with all the readers of\n",
      "the daily press, I knew little of my former friend and companion.\n",
      "\n",
      "One night—it was on the twentieth of March, 1888—I was returning from a\n",
      "journey to a patient (for I had now returned to civil practice), when\n",
      "my way led me through Baker Street. As I passed the well-remembered\n",
      "door, which must always be associated in my mind with my wooing, and\n",
      "with the dark incidents of the Study in Scarlet, I was seized with a\n",
      "keen desire to see Holmes again, and to know how he was employing his\n",
      "extraordinary powers. His rooms were brilliantly lit, and, even as I\n",
      "looked up, I saw his tall, spare figure pass twice in a dark silhouette\n",
      "against the blind. He was pacing the room swiftly, eagerly, with his\n",
      "head sunk upon his chest and his hands clasped behind him. To me, who\n",
      "knew his every mood and habit, his attitude and manner told their own\n",
      "story. He was at work again. He had risen out of his drug-created\n",
      "dreams and was hot upon the scent of some new problem. I rang the bell\n",
      "and was shown up to the chamber which had formerly been in part my own.\n",
      "\n",
      "His manner was not effusive. It seldom was; but he was glad, I think,\n",
      "to see me. With hardly a word spoken, but with a kindly eye, he waved\n",
      "me to an armchair, threw across his case of cigars, and indicated a\n",
      "spirit case and a gasogene in the corner. Then he stood before the fire\n",
      "and looked me over in his singular introspective fashion.\n",
      "\n",
      "“Wedlock suits you,” he remarked. “I think, Watson, that you have put\n",
      "on seven and a half pounds since I saw you.”\n",
      "\n",
      "“Seven!” I answered.\n",
      "\n",
      "“Indeed, I should have thought a little more. Just a trifle more, I\n",
      "fancy, Watson. And in practice again, I observe. You did not tell me\n",
      "that you intended to go into harness.”\n",
      "\n",
      "“Then, how do you know?”\n",
      "\n",
      "“I see it, I deduce it. How do I know that you have been getting\n",
      "yourself very wet lately, and that you have a most clumsy and careless\n",
      "servant girl?”\n",
      "\n",
      "“My dear Holmes,” said I, “this is too much. You would certainly have\n",
      "been burned, had you lived a few centuries ago. It is true that I had a\n",
      "country walk on Thursday and came home in a dreadful mess, but as I\n",
      "have changed my clothes I can’t imagine how you deduce it. As to Mary\n",
      "Jane, she is incorrigible, and my wife has given her notice, but there,\n",
      "again, I fail to see how you work it out.”\n",
      "\n",
      "He chuckled to himself and rubbed his long, nervous hands together.\n",
      "\n",
      "“It is simplicity itself,” said he; “my eyes tell me that on the inside\n",
      "of your left shoe, just where the firelight strikes it, the leather is\n",
      "scored by six almost parallel cuts. Obviously they have been caused by\n",
      "someone who has very carelessly scraped round the edges of the sole in\n",
      "order to remove crusted mud from it. Hence, you see, my double\n",
      "deduction that you had been out in vile weather, and that you had a\n",
      "particularly malignant boot-slitting specimen of the London slavey. As\n",
      "to your practice, if a gentleman walks into my rooms smelling of\n",
      "iodoform, with a black mark of nitrate of silver upon his right\n",
      "forefinger, and a bulge on the right side of his top-hat to show where\n",
      "he has secreted his stethoscope, I must be dull, indeed, if I do not\n",
      "pronounce him to be an active member of the medical profession.”\n",
      "\n",
      "I could not help laughing at the ease with which he explained his\n",
      "process of deduction. “When I hear you give your reasons,” I remarked,\n",
      "“the thing always appears to me to be so ridiculously simple that I\n",
      "could easily do it myself, though at each successive instance of your\n",
      "reasoning I am baffled until you explain your process. And yet I\n",
      "believe that my eyes are as good as yours.”\n",
      "\n",
      "“Quite so,” he answered, lighting a cigarette, and throwing himself\n",
      "down into an armchair. “You see, but you do not observe. The\n",
      "distinction is clear. For example, you have frequently seen the steps\n",
      "which lead up from the hall to this room.”\n",
      "\n",
      "“Frequently.”\n",
      "\n",
      "“How often?”\n",
      "\n",
      "“Well, some hundreds of times.”\n",
      "\n",
      "“Then how many are there?”\n",
      "\n",
      "“How many? I don’t know.”\n",
      "\n",
      "“Quite so! You have not observed. And yet you have seen. That is just\n",
      "my point. Now, I know that there are seventeen steps, because I have\n",
      "both seen and observed. By the way, since you are interested in these\n",
      "little problems, and since you are good enough to chronicle one or two\n",
      "of my trifling experiences, you may be interested in this.” He threw\n",
      "over a sheet of thick, pink-tinted notepaper which had been lying open\n",
      "upon the table. “It came by the last post,” said he. “Read it aloud.”\n",
      "\n",
      "The note was undated, and without either signature or address.\n",
      "\n",
      "“There will call upon you to-night, at a quarter to eight o’clock,” it\n",
      "said, “a gentleman who desires to consult you upon a matter of the very\n",
      "deepest moment. Your recent services to one of the royal houses of\n",
      "Europe have shown that you are one who may safely be trusted with\n",
      "matters which are of an importance which can hardly be exaggerated.\n",
      "This account of you we have from all quarters received. Be in your\n",
      "chamber then at that hour, and do not take it amiss if your visitor\n",
      "wear a mask.”\n",
      "\n",
      "“This is indeed a mystery,” I remarked. “What do you imagine that it\n",
      "means?”\n",
      "\n",
      "“I have no data yet. It is a capital mistake to theorise before one has\n",
      "data. Insensibly one begins to twist facts to suit theories, instead of\n",
      "theories to suit facts. But the note itself. What do you deduce from\n",
      "it?”\n",
      "\n",
      "I carefully examined the writing, and the paper upon which it was\n",
      "written.\n",
      "\n",
      "“The man who wrote it was presumably well to do,” I remarked,\n",
      "endeavouring to imitate my companion’s processes. “Such paper could not\n",
      "be bought under half a crown a packet. It is peculiarly strong and\n",
      "stiff.”\n",
      "\n",
      "“Peculiar—that is the very word,” said Holmes. “It is not an English\n",
      "paper at all. Hold it up to the light.”\n",
      "\n",
      "I did so, and saw a large “E” with a small “g,” a “P,” and a large “G”\n",
      "with a small “t” woven into the texture of the paper.\n",
      "\n",
      "“What do you make of that?” asked Holmes.\n",
      "\n",
      "“The name of the maker, no doubt; or his monogram, rather.”\n",
      "\n",
      "“Not at all. The ‘G’ with the small ‘t’ stands for ‘Gesellschaft,’\n",
      "which is the German for ‘Company.’ It is a customary contraction like\n",
      "our ‘Co.’ ‘P,’ of course, stands for ‘Papier.’ Now for the ‘Eg.’ Let us\n",
      "glance at our Continental Gazetteer.” He took down a heavy brown volume\n",
      "from his shelves. “Eglow, Eglonitz—here we are, Egria. It is in a\n",
      "German-speaking country—in Bohemia, not far from Carlsbad. ‘Remarkable\n",
      "as being the scene of the death of Wallenstein, and for its numerous\n",
      "glass-factories and paper-mills.’ Ha, ha, my boy, what do you make of\n",
      "that?” His eyes sparkled, and he sent up a great blue triumphant cloud\n",
      "from his cigarette.\n",
      "\n",
      "“The paper was made in Bohemia,” I said.\n",
      "\n",
      "“Precisely. And the man who wrote the note is a German. Do you note the\n",
      "peculiar construction of the sentence—‘This account of you we have from\n",
      "all quarters received.’ A Frenchman or Russian could not have written\n",
      "that. It is the German who is so uncourteous to his verbs. It only\n",
      "remains, therefore, to discover what is wanted by this German who\n",
      "writes upon Bohemian paper and prefers wearing a mask to showing his\n",
      "face. And here he comes, if I am not mistaken, to resolve all our\n",
      "doubts.”\n",
      "\n",
      "As he spoke there was the sharp sound of horses’ hoofs and grating\n",
      "wheels against the curb, followed by a sharp pull at the bell. Holmes\n",
      "whistled.\n",
      "\n",
      "“A pair, by the sound,” said he. “Yes,” he continued, glancing out of\n",
      "the window. “A nice little brougham and a pair of beauties. A hundred\n",
      "and fifty guineas apiece. There’s money in this case, Watson, if there\n",
      "is nothing else.”\n",
      "\n",
      "“I think that I had better go, Holmes.”\n",
      "\n",
      "“Not a bit, Doctor. Stay where you are. I am lost without my Boswell.\n",
      "And this promises to be interesting. It would be a pity to miss it.”\n",
      "\n",
      "“But your client—”\n",
      "\n",
      "“Never mind him. I may want your help, and so may he. Here he comes.\n",
      "Sit down in that armchair, Doctor, and give us your best attention.”\n",
      "\n",
      "A slow and heavy step, which had been heard upon the stairs and in the\n",
      "passage, paused immediately outside the door. Then there was a loud and\n",
      "authoritative tap.\n",
      "\n",
      "“Come in!” said Holmes.\n",
      "\n",
      "A man entered who could hardly have been less than six feet six inches\n",
      "in height, with the chest and limbs of a Hercules. His dress was rich\n",
      "with a richness which would, in England, be looked upon as akin to bad\n",
      "taste. Heavy bands of astrakhan were slashed across the sleeves and\n",
      "fronts of his double-breasted coat, while the deep blue cloak which was\n",
      "thrown over his shoulders was lined with flame-coloured silk and\n",
      "secured at the neck with a brooch which consisted of a single flaming\n",
      "beryl. Boots which extended halfway up his calves, and which were\n",
      "trimmed at the tops with rich brown fur, completed the impression of\n",
      "barbaric opulence which was suggested by his whole appearance. He\n",
      "carried a broad-brimmed hat in his hand, while he wore across the upper\n",
      "part of his face, extending down past the cheekbones, a black vizard\n",
      "mask, which he had apparently adjusted that very moment, for his hand\n",
      "was still raised to it as he entered. From the lower part of the face\n",
      "he appeared to be a man of strong character, with a thick, hanging lip,\n",
      "and a long, straight chin suggestive of resolution pushed to the length\n",
      "of obstinacy.\n",
      "\n",
      "“You had my note?” he asked with a deep harsh voice and a strongly\n",
      "marked German accent. “I told you that I would call.” He looked from\n",
      "one to the other of us, as if uncertain which to address.\n",
      "\n",
      "“Pray take a seat,” said Holmes. “This is my friend and colleague, Dr.\n",
      "Watson, who is occasionally good enough to help me in my cases. Whom\n",
      "have I the honour to address?”\n",
      "\n",
      "“You may address me as the Count Von Kramm, a Bohemian nobleman. I\n",
      "understand that this gentleman, your friend, is a man of honour and\n",
      "discretion, whom I may trust with a matter of the most extreme\n",
      "importance. If not, I should much prefer to communicate with you\n",
      "alone.”\n",
      "\n",
      "I rose to go, but Holmes caught me by the wrist and pushed me back into\n",
      "my chair. “It is both, or none,” said he. “You may say before this\n",
      "gentleman anything which you may say to me.”\n",
      "\n",
      "The Count shrugged his broad shoulders. “Then I must begin,” said he,\n",
      "“by binding you both to absolute secrecy for two years; at the end of\n",
      "that time the matter will be of no importance. At present it is not too\n",
      "much to say that it is of such weight it may have an influence upon\n",
      "European history.”\n",
      "\n",
      "“I promise,” said Holmes.\n",
      "\n",
      "“And I.”\n",
      "\n",
      "“You will excuse this mask,” continued our strange visitor. “The august\n",
      "person who employs me wishes his agent to be unknown to you, and I may\n",
      "confess at once that the title by which I have just called myself is\n",
      "not exactly my own.”\n",
      "\n",
      "“I was aware of it,” said Holmes dryly.\n",
      "\n",
      "“The circumstances are of great delicacy, and every precaution has to\n",
      "be taken to quench what might grow to be an immense scandal and\n",
      "seriously compromise one of the reigning families of Europe. To speak\n",
      "plainly, the matter implicates the great House of Ormstein, hereditary\n",
      "kings of Bohemia.”\n",
      "\n",
      "“I was also aware of that,” murmured Holmes, settling himself down in\n",
      "his armchair and closing his eyes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in faqs.split('\\n'):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4192b174-e2e5-4db2-86fc-17096d31aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences=[]\n",
    "for sentence in faqs.split('\\n'):\n",
    "    tokenized_sentence= tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1, len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a8ad4357-9596-4bf7-873c-c924530f1511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[80, 289],\n",
       " [80, 289, 1],\n",
       " [80, 289, 1, 81],\n",
       " [80, 289, 1, 81, 2],\n",
       " [80, 289, 1, 81, 2, 62],\n",
       " [80, 289, 1, 81, 2, 62, 20],\n",
       " [80, 289, 1, 81, 2, 62, 20, 26],\n",
       " [80, 289, 1, 81, 2, 62, 20, 26, 98],\n",
       " [80, 289, 1, 81, 2, 62, 20, 26, 98, 99],\n",
       " [80, 289, 1, 81, 2, 62, 20, 26, 98, 99, 100],\n",
       " [32, 82],\n",
       " [32, 82, 15],\n",
       " [32, 82, 15, 27],\n",
       " [32, 82, 15, 27, 1],\n",
       " [32, 82, 15, 27, 1, 157],\n",
       " [32, 82, 15, 27, 1, 157, 2],\n",
       " [32, 82, 15, 27, 1, 157, 2, 290],\n",
       " [32, 82, 15, 27, 1, 157, 2, 290, 291],\n",
       " [32, 82, 15, 27, 1, 157, 2, 290, 291, 22],\n",
       " [32, 82, 15, 27, 1, 157, 2, 290, 291, 22, 63],\n",
       " [32, 82, 15, 27, 1, 157, 2, 290, 291, 22, 63, 292],\n",
       " [32, 82, 15, 27, 1, 157, 2, 290, 291, 22, 63, 292, 3],\n",
       " [32, 82, 15, 27, 1, 157, 2, 290, 291, 22, 63, 292, 3, 16],\n",
       " [158, 63],\n",
       " [158, 63, 293],\n",
       " [158, 63, 293, 294],\n",
       " [158, 63, 293, 294, 9],\n",
       " [158, 63, 293, 294, 9, 33],\n",
       " [158, 63, 293, 294, 9, 33, 295],\n",
       " [158, 63, 293, 294, 9, 33, 295, 11],\n",
       " [158, 63, 293, 294, 9, 33, 295, 11, 101],\n",
       " [158, 63, 293, 294, 9, 33, 295, 11, 101, 11],\n",
       " [158, 63, 293, 294, 9, 33, 295, 11, 101, 11, 159],\n",
       " [158, 63, 293, 294, 9, 33, 295, 11, 101, 11, 159, 43],\n",
       " [296, 157],\n",
       " [296, 157, 11],\n",
       " [296, 157, 11, 102],\n",
       " [296, 157, 11, 102, 1],\n",
       " [296, 157, 11, 102, 1, 297],\n",
       " [296, 157, 11, 102, 1, 297, 2],\n",
       " [296, 157, 11, 102, 1, 297, 2, 1],\n",
       " [296, 157, 11, 102, 1, 297, 2, 1, 80],\n",
       " [296, 157, 11, 102, 1, 297, 2, 1, 80, 83],\n",
       " [296, 157, 11, 102, 1, 297, 2, 1, 80, 83, 298],\n",
       " [296, 157, 11, 102, 1, 297, 2, 1, 80, 83, 298, 299],\n",
       " [16, 32],\n",
       " [16, 32, 82],\n",
       " [16, 32, 82, 43],\n",
       " [16, 32, 82, 43, 300],\n",
       " [16, 32, 82, 43, 300, 22],\n",
       " [16, 32, 82, 43, 300, 22, 301],\n",
       " [16, 32, 82, 43, 300, 22, 301, 83],\n",
       " [16, 32, 82, 43, 300, 22, 301, 83, 302],\n",
       " [160, 1],\n",
       " [160, 1, 81],\n",
       " [160, 1, 81, 2],\n",
       " [160, 1, 81, 2, 62],\n",
       " [160, 1, 81, 2, 62, 20],\n",
       " [303, 98],\n",
       " [303, 98, 99],\n",
       " [303, 98, 99, 100],\n",
       " [304, 305],\n",
       " [304, 305, 306],\n",
       " [304, 305, 306, 307],\n",
       " [304, 305, 306, 307, 308],\n",
       " [304, 305, 306, 307, 308, 82],\n",
       " [304, 305, 306, 307, 308, 82, 309],\n",
       " [161, 310],\n",
       " [161, 310, 33],\n",
       " [161, 310, 33, 311],\n",
       " [161, 310, 33, 311, 312],\n",
       " [313, 162],\n",
       " [163, 314],\n",
       " [163, 314, 315],\n",
       " [163, 314, 315, 316],\n",
       " [163, 314, 315, 316, 317],\n",
       " [318, 2],\n",
       " [318, 2, 32],\n",
       " [318, 2, 32, 80],\n",
       " [318, 2, 32, 80, 83],\n",
       " [318, 2, 32, 80, 83, 82],\n",
       " [318, 2, 32, 80, 83, 82, 1],\n",
       " [318, 2, 32, 80, 83, 82, 1, 81],\n",
       " [318, 2, 32, 80, 83, 82, 1, 81, 2],\n",
       " [318, 2, 32, 80, 83, 82, 1, 81, 2, 62],\n",
       " [318, 2, 32, 80, 83, 82, 1, 81, 2, 62, 20],\n",
       " [319, 26],\n",
       " [319, 26, 44],\n",
       " [319, 26, 44, 320],\n",
       " [319, 26, 44, 320, 80],\n",
       " [319, 26, 44, 320, 80, 83],\n",
       " [319, 26, 44, 320, 80, 83, 321],\n",
       " [319, 26, 44, 320, 80, 83, 321, 3],\n",
       " [319, 26, 44, 320, 80, 83, 321, 3, 322],\n",
       " [319, 26, 44, 320, 80, 83, 321, 3, 322, 323],\n",
       " [1, 81],\n",
       " [1, 81, 2],\n",
       " [1, 81, 2, 62],\n",
       " [1, 81, 2, 62, 20],\n",
       " [26, 98],\n",
       " [26, 98, 99],\n",
       " [26, 98, 99, 100],\n",
       " [7, 4],\n",
       " [7, 4, 103],\n",
       " [7, 4, 103, 12],\n",
       " [7, 4, 103, 12, 64],\n",
       " [326, 1],\n",
       " [326, 1, 327],\n",
       " [326, 1, 327, 328],\n",
       " [326, 1, 327, 328, 329],\n",
       " [330, 4],\n",
       " [330, 4, 65],\n",
       " [330, 4, 65, 2],\n",
       " [330, 4, 65, 2, 331],\n",
       " [332, 1],\n",
       " [332, 1, 333],\n",
       " [332, 1, 333, 334],\n",
       " [332, 1, 333, 334, 164],\n",
       " [335, 1],\n",
       " [335, 1, 336],\n",
       " [335, 1, 336, 337],\n",
       " [335, 1, 336, 337, 338],\n",
       " [339, 1],\n",
       " [339, 1, 48],\n",
       " [339, 1, 48, 16],\n",
       " [339, 1, 48, 16, 1],\n",
       " [339, 1, 48, 16, 1, 340],\n",
       " [339, 1, 48, 16, 1, 340, 165],\n",
       " [341, 1],\n",
       " [341, 1, 53],\n",
       " [341, 1, 53, 2],\n",
       " [341, 1, 53, 2, 1],\n",
       " [341, 1, 53, 2, 1, 104],\n",
       " [341, 1, 53, 2, 1, 104, 342],\n",
       " [343, 1],\n",
       " [343, 1, 53],\n",
       " [343, 1, 53, 2],\n",
       " [343, 1, 53, 2, 1],\n",
       " [343, 1, 53, 2, 1, 344],\n",
       " [343, 1, 53, 2, 1, 344, 345],\n",
       " [346, 1],\n",
       " [346, 1, 53],\n",
       " [346, 1, 53, 2],\n",
       " [346, 1, 53, 2, 1],\n",
       " [346, 1, 53, 2, 1, 347],\n",
       " [346, 1, 53, 2, 1, 347, 348],\n",
       " [349, 1],\n",
       " [349, 1, 53],\n",
       " [349, 1, 53, 2],\n",
       " [349, 1, 53, 2, 1],\n",
       " [349, 1, 53, 2, 1, 350],\n",
       " [349, 1, 53, 2, 1, 350, 351],\n",
       " [352, 1],\n",
       " [352, 1, 53],\n",
       " [352, 1, 53, 2],\n",
       " [352, 1, 53, 2, 1],\n",
       " [352, 1, 53, 2, 1, 166],\n",
       " [352, 1, 53, 2, 1, 166, 353],\n",
       " [354, 1],\n",
       " [354, 1, 53],\n",
       " [354, 1, 53, 2],\n",
       " [354, 1, 53, 2, 1],\n",
       " [354, 1, 53, 2, 1, 355],\n",
       " [354, 1, 53, 2, 1, 355, 356],\n",
       " [7, 4],\n",
       " [7, 4, 103],\n",
       " [7, 4, 103, 12],\n",
       " [7, 4, 103, 12, 64],\n",
       " [5, 62],\n",
       " [5, 62, 20],\n",
       " [5, 62, 20, 105],\n",
       " [5, 62, 20, 105, 15],\n",
       " [5, 62, 20, 105, 15, 106],\n",
       " [5, 62, 20, 105, 15, 106, 1],\n",
       " [5, 62, 20, 105, 15, 106, 1, 107],\n",
       " [5, 62, 20, 105, 15, 106, 1, 107, 7],\n",
       " [5, 62, 20, 105, 15, 106, 1, 107, 7, 19],\n",
       " [5, 62, 20, 105, 15, 106, 1, 107, 7, 19, 167],\n",
       " [5, 62, 20, 105, 15, 106, 1, 107, 7, 19, 167, 108],\n",
       " [5, 62, 20, 105, 15, 106, 1, 107, 7, 19, 167, 108, 66],\n",
       " [357, 109],\n",
       " [357, 109, 102],\n",
       " [357, 109, 102, 168],\n",
       " [357, 109, 102, 168, 110],\n",
       " [357, 109, 102, 168, 110, 169],\n",
       " [357, 109, 102, 168, 110, 169, 12],\n",
       " [357, 109, 102, 168, 110, 169, 12, 8],\n",
       " [357, 109, 102, 168, 110, 169, 12, 8, 67],\n",
       " [357, 109, 102, 168, 110, 169, 12, 8, 67, 105],\n",
       " [357, 109, 102, 168, 110, 169, 12, 8, 67, 105, 358],\n",
       " [357, 109, 102, 168, 110, 169, 12, 8, 67, 105, 358, 3],\n",
       " [359, 1],\n",
       " [359, 1, 111],\n",
       " [359, 1, 111, 2],\n",
       " [359, 1, 111, 2, 109],\n",
       " [359, 1, 111, 2, 109, 360],\n",
       " [359, 1, 111, 2, 109, 360, 11],\n",
       " [359, 1, 111, 2, 109, 360, 11, 14],\n",
       " [359, 1, 111, 2, 109, 360, 11, 14, 23],\n",
       " [359, 1, 111, 2, 109, 360, 11, 14, 23, 13],\n",
       " [359, 1, 111, 2, 109, 360, 11, 14, 23, 13, 10],\n",
       " [359, 1, 111, 2, 109, 360, 11, 14, 23, 13, 10, 361],\n",
       " [359, 1, 111, 2, 109, 360, 11, 14, 23, 13, 10, 361, 168],\n",
       " [359, 1, 111, 2, 109, 360, 11, 14, 23, 13, 10, 361, 168, 170],\n",
       " [171, 5],\n",
       " [171, 5, 362],\n",
       " [171, 5, 362, 27],\n",
       " [171, 5, 362, 27, 172],\n",
       " [171, 5, 362, 27, 172, 173],\n",
       " [171, 5, 362, 27, 172, 173, 40],\n",
       " [171, 5, 362, 27, 172, 173, 40, 363],\n",
       " [171, 5, 362, 27, 172, 173, 40, 363, 3],\n",
       " [171, 5, 362, 27, 172, 173, 40, 363, 3, 13],\n",
       " [171, 5, 362, 27, 172, 173, 40, 363, 3, 13, 37],\n",
       " [171, 5, 362, 27, 172, 173, 40, 363, 3, 13, 37, 174],\n",
       " [54, 364],\n",
       " [54, 364, 5],\n",
       " [54, 364, 5, 8],\n",
       " [54, 364, 5, 8, 365],\n",
       " [54, 364, 5, 8, 365, 366],\n",
       " [54, 364, 5, 8, 365, 366, 38],\n",
       " [54, 364, 5, 8, 365, 366, 38, 367],\n",
       " [54, 364, 5, 8, 365, 366, 38, 367, 368],\n",
       " [54, 364, 5, 8, 365, 366, 38, 367, 368, 112],\n",
       " [54, 364, 5, 8, 365, 366, 38, 367, 368, 112, 10],\n",
       " [14, 7],\n",
       " [14, 7, 113],\n",
       " [14, 7, 113, 11],\n",
       " [14, 7, 113, 11, 1],\n",
       " [14, 7, 113, 11, 1, 114],\n",
       " [14, 7, 113, 11, 1, 114, 369],\n",
       " [14, 7, 113, 11, 1, 114, 369, 175],\n",
       " [14, 7, 113, 11, 1, 114, 369, 175, 3],\n",
       " [14, 7, 113, 11, 1, 114, 369, 175, 3, 370],\n",
       " [14, 7, 113, 11, 1, 114, 369, 175, 3, 370, 371],\n",
       " [14, 7, 113, 11, 1, 114, 369, 175, 3, 370, 371, 13],\n",
       " [1, 372],\n",
       " [1, 372, 55],\n",
       " [1, 372, 55, 68],\n",
       " [1, 372, 55, 68, 38],\n",
       " [1, 372, 55, 68, 38, 24],\n",
       " [1, 372, 55, 68, 38, 24, 4],\n",
       " [1, 372, 55, 68, 38, 24, 4, 373],\n",
       " [1, 372, 55, 68, 38, 24, 4, 373, 10],\n",
       " [1, 372, 55, 68, 38, 24, 4, 373, 10, 56],\n",
       " [1, 372, 55, 68, 38, 24, 4, 373, 10, 56, 19],\n",
       " [1, 372, 55, 68, 38, 24, 4, 373, 10, 56, 19, 374],\n",
       " [1, 372, 55, 68, 38, 24, 4, 373, 10, 56, 19, 374, 69],\n",
       " [1, 372, 55, 68, 38, 24, 4, 373, 10, 56, 19, 374, 69, 12],\n",
       " [1, 372, 55, 68, 38, 24, 4, 373, 10, 56, 19, 374, 69, 12, 4],\n",
       " [375, 376],\n",
       " [375, 376, 10],\n",
       " [375, 376, 10, 377],\n",
       " [375, 376, 10, 377, 176],\n",
       " [375, 376, 10, 377, 176, 2],\n",
       " [375, 376, 10, 377, 176, 2, 1],\n",
       " [375, 376, 10, 377, 176, 2, 1, 378],\n",
       " [375, 376, 10, 377, 176, 2, 1, 378, 379],\n",
       " [375, 376, 10, 377, 176, 2, 1, 378, 379, 380],\n",
       " [375, 376, 10, 377, 176, 2, 1, 378, 379, 380, 16],\n",
       " [375, 376, 10, 377, 176, 2, 1, 378, 379, 380, 16, 4],\n",
       " [375, 376, 10, 377, 176, 2, 1, 378, 379, 380, 16, 4, 381],\n",
       " [3, 4],\n",
       " [3, 4, 382],\n",
       " [3, 4, 382, 177],\n",
       " [3, 4, 382, 177, 54],\n",
       " [3, 4, 382, 177, 54, 383],\n",
       " [3, 4, 382, 177, 54, 383, 384],\n",
       " [3, 4, 382, 177, 54, 383, 384, 27],\n",
       " [3, 4, 382, 177, 54, 383, 384, 27, 1],\n",
       " [3, 4, 382, 177, 54, 383, 384, 27, 1, 385],\n",
       " [3, 4, 382, 177, 54, 383, 384, 27, 1, 385, 27],\n",
       " [386, 1],\n",
       " [386, 1, 387],\n",
       " [386, 1, 387, 28],\n",
       " [386, 1, 387, 28, 388],\n",
       " [386, 1, 387, 28, 388, 389],\n",
       " [386, 1, 387, 28, 388, 389, 3],\n",
       " [386, 1, 387, 28, 388, 389, 3, 390],\n",
       " [386, 1, 387, 28, 388, 389, 3, 390, 38],\n",
       " [386, 1, 387, 28, 388, 389, 3, 390, 38, 27],\n",
       " [386, 1, 387, 28, 388, 389, 3, 390, 38, 27, 1],\n",
       " [386, 1, 387, 28, 388, 389, 3, 390, 38, 27, 1, 391],\n",
       " [392, 5],\n",
       " [392, 5, 393],\n",
       " [392, 5, 393, 115],\n",
       " [392, 5, 393, 115, 394],\n",
       " [392, 5, 393, 115, 394, 57],\n",
       " [392, 5, 393, 115, 394, 57, 8],\n",
       " [392, 5, 393, 115, 394, 57, 8, 45],\n",
       " [392, 5, 393, 115, 394, 57, 8, 45, 395],\n",
       " [392, 5, 393, 115, 394, 57, 8, 45, 395, 3],\n",
       " [392, 5, 393, 115, 394, 57, 8, 45, 395, 3, 396],\n",
       " [178, 397],\n",
       " [178, 397, 14],\n",
       " [178, 397, 14, 5],\n",
       " [178, 397, 14, 5, 398],\n",
       " [178, 397, 14, 5, 398, 4],\n",
       " [178, 397, 14, 5, 398, 4, 399],\n",
       " [178, 397, 14, 5, 398, 4, 399, 400],\n",
       " [178, 397, 14, 5, 398, 4, 399, 400, 17],\n",
       " [178, 397, 14, 5, 398, 4, 399, 400, 17, 179],\n",
       " [401, 4],\n",
       " [401, 4, 180],\n",
       " [401, 4, 180, 34],\n",
       " [401, 4, 180, 34, 40],\n",
       " [401, 4, 180, 34, 40, 8],\n",
       " [401, 4, 180, 34, 40, 8, 402],\n",
       " [401, 4, 180, 34, 40, 8, 402, 403],\n",
       " [401, 4, 180, 34, 40, 8, 402, 403, 404],\n",
       " [401, 4, 180, 34, 40, 8, 402, 403, 404, 12],\n",
       " [401, 4, 180, 34, 40, 8, 402, 403, 404, 12, 4],\n",
       " [401, 4, 180, 34, 40, 8, 402, 403, 404, 12, 4, 405],\n",
       " [406, 43],\n",
       " [406, 43, 4],\n",
       " [406, 43, 4, 407],\n",
       " [406, 43, 4, 407, 12],\n",
       " [406, 43, 4, 407, 12, 37],\n",
       " [406, 43, 4, 407, 12, 37, 2],\n",
       " [406, 43, 4, 407, 12, 37, 2, 8],\n",
       " [406, 43, 4, 407, 12, 37, 2, 8, 45],\n",
       " [406, 43, 4, 407, 12, 37, 2, 8, 45, 408],\n",
       " [406, 43, 4, 407, 12, 37, 2, 8, 45, 408, 409],\n",
       " [406, 43, 4, 407, 12, 37, 2, 8, 45, 408, 409, 410],\n",
       " [406, 43, 4, 407, 12, 37, 2, 8, 45, 408, 409, 410, 56],\n",
       " [406, 43, 4, 407, 12, 37, 2, 8, 45, 408, 409, 410, 56, 23],\n",
       " [21, 116],\n",
       " [21, 116, 411],\n",
       " [21, 116, 411, 181],\n",
       " [21, 116, 411, 181, 4],\n",
       " [21, 116, 411, 181, 4, 117],\n",
       " [21, 116, 411, 181, 4, 117, 170],\n",
       " [21, 116, 411, 181, 4, 117, 170, 12],\n",
       " [21, 116, 411, 181, 4, 117, 170, 12, 4],\n",
       " [21, 116, 411, 181, 4, 117, 170, 12, 4, 182],\n",
       " [21, 116, 411, 181, 4, 117, 170, 12, 4, 182, 115],\n",
       " [21, 116, 411, 181, 4, 117, 170, 12, 4, 182, 115, 24],\n",
       " [21, 116, 411, 181, 4, 117, 170, 12, 4, 182, 115, 24, 8],\n",
       " [21, 116, 411, 181, 4, 117, 170, 12, 4, 182, 115, 24, 8, 3],\n",
       " [84, 49],\n",
       " [84, 49, 14],\n",
       " [84, 49, 14, 38],\n",
       " [84, 49, 14, 38, 37],\n",
       " [84, 49, 14, 38, 37, 107],\n",
       " [84, 49, 14, 38, 37, 107, 5],\n",
       " [84, 49, 14, 38, 37, 107, 5, 66],\n",
       " [84, 49, 14, 38, 37, 107, 5, 66, 3],\n",
       " [84, 49, 14, 38, 37, 107, 5, 66, 3, 13],\n",
       " [84, 49, 14, 38, 37, 107, 5, 66, 3, 13, 107],\n",
       " [84, 49, 14, 38, 37, 107, 5, 66, 3, 13, 107, 14],\n",
       " [84, 49, 14, 38, 37, 107, 5, 66, 3, 13, 107, 14, 1],\n",
       " [84, 49, 14, 38, 37, 107, 5, 66, 3, 13, 107, 14, 1, 412],\n",
       " [84, 49, 14, 38, 37, 107, 5, 66, 3, 13, 107, 14, 1, 412, 172],\n",
       " [173, 2],\n",
       " [173, 2, 413],\n",
       " [173, 2, 413, 3],\n",
       " [173, 2, 413, 3, 414],\n",
       " [173, 2, 413, 3, 414, 415],\n",
       " [7, 25],\n",
       " [7, 25, 68],\n",
       " [7, 25, 68, 70],\n",
       " [7, 25, 68, 70, 2],\n",
       " [7, 25, 68, 70, 2, 20],\n",
       " [7, 25, 68, 70, 2, 20, 183],\n",
       " [7, 25, 68, 70, 2, 20, 183, 18],\n",
       " [7, 25, 68, 70, 2, 20, 183, 18, 416],\n",
       " [7, 25, 68, 70, 2, 20, 183, 18, 416, 25],\n",
       " [7, 25, 68, 70, 2, 20, 183, 18, 416, 25, 417],\n",
       " [7, 25, 68, 70, 2, 20, 183, 18, 416, 25, 417, 85],\n",
       " [7, 25, 68, 70, 2, 20, 183, 18, 416, 25, 417, 85, 159],\n",
       " [28, 184],\n",
       " [28, 184, 110],\n",
       " [28, 184, 110, 18],\n",
       " [28, 184, 110, 18, 45],\n",
       " [28, 184, 110, 18, 45, 418],\n",
       " [28, 184, 110, 18, 45, 418, 419],\n",
       " [28, 184, 110, 18, 45, 418, 419, 3],\n",
       " [28, 184, 110, 18, 45, 418, 419, 3, 1],\n",
       " [28, 184, 110, 18, 45, 418, 419, 3, 1, 185],\n",
       " [28, 184, 110, 18, 45, 418, 419, 3, 1, 185, 420],\n",
       " [421, 17],\n",
       " [421, 17, 422],\n",
       " [421, 17, 422, 41],\n",
       " [421, 17, 422, 41, 423],\n",
       " [421, 17, 422, 41, 423, 1],\n",
       " [421, 17, 422, 41, 423, 1, 48],\n",
       " [421, 17, 422, 41, 423, 1, 48, 30],\n",
       " [421, 17, 422, 41, 423, 1, 48, 30, 424],\n",
       " [421, 17, 422, 41, 423, 1, 48, 30, 424, 425],\n",
       " [421, 17, 422, 41, 423, 1, 48, 30, 424, 425, 69],\n",
       " [421, 17, 422, 41, 423, 1, 48, 30, 424, 425, 69, 426],\n",
       " [2, 8],\n",
       " [2, 8, 45],\n",
       " [2, 8, 45, 427],\n",
       " [2, 8, 45, 427, 54],\n",
       " [2, 8, 45, 427, 54, 428],\n",
       " [2, 8, 45, 427, 54, 428, 5],\n",
       " [2, 8, 45, 427, 54, 428, 5, 429],\n",
       " [2, 8, 45, 427, 54, 428, 5, 429, 40],\n",
       " [2, 8, 45, 427, 54, 428, 5, 429, 40, 18],\n",
       " [2, 8, 45, 427, 54, 428, 5, 429, 40, 18, 186],\n",
       " [118, 20],\n",
       " [118, 20, 30],\n",
       " [118, 20, 30, 430],\n",
       " [118, 20, 30, 430, 119],\n",
       " [118, 20, 30, 430, 119, 431],\n",
       " [118, 20, 30, 430, 119, 431, 2],\n",
       " [118, 20, 30, 430, 119, 431, 2, 432],\n",
       " [118, 20, 30, 430, 119, 431, 2, 432, 16],\n",
       " [118, 20, 30, 430, 119, 431, 2, 432, 16, 8],\n",
       " [118, 20, 30, 430, 119, 431, 2, 432, 16, 8, 111],\n",
       " [118, 20, 30, 430, 119, 431, 2, 432, 16, 8, 111, 120],\n",
       " [433, 434],\n",
       " [433, 434, 12],\n",
       " [433, 434, 12, 71],\n",
       " [433, 434, 12, 71, 435],\n",
       " [433, 434, 12, 71, 435, 12],\n",
       " [433, 434, 12, 71, 435, 12, 187],\n",
       " [433, 434, 12, 71, 435, 12, 187, 188],\n",
       " [433, 434, 12, 71, 435, 12, 187, 188, 436],\n",
       " [433, 434, 12, 71, 435, 12, 187, 188, 436, 437],\n",
       " [433, 434, 12, 71, 435, 12, 187, 188, 436, 437, 8],\n",
       " [433, 434, 12, 71, 435, 12, 187, 188, 436, 437, 8, 438],\n",
       " [439, 3],\n",
       " [439, 3, 440],\n",
       " [439, 3, 440, 28],\n",
       " [439, 3, 440, 28, 189],\n",
       " [439, 3, 440, 28, 189, 5],\n",
       " [439, 3, 440, 28, 189, 5, 189],\n",
       " [439, 3, 440, 28, 189, 5, 189, 441],\n",
       " [439, 3, 440, 28, 189, 5, 189, 441, 442],\n",
       " [439, 3, 440, 28, 189, 5, 189, 441, 442, 3],\n",
       " [439, 3, 440, 28, 189, 5, 189, 441, 442, 3, 443],\n",
       " [1, 444],\n",
       " [1, 444, 2],\n",
       " [1, 444, 2, 1],\n",
       " [1, 444, 2, 1, 190],\n",
       " [1, 444, 2, 1, 190, 3],\n",
       " [1, 444, 2, 1, 190, 3, 1],\n",
       " [1, 444, 2, 1, 190, 3, 1, 445],\n",
       " [1, 444, 2, 1, 190, 3, 1, 445, 446],\n",
       " [1, 444, 2, 1, 190, 3, 1, 445, 446, 2],\n",
       " [1, 444, 2, 1, 190, 3, 1, 445, 446, 2, 8],\n",
       " [1, 444, 2, 1, 190, 3, 1, 445, 446, 2, 8, 45],\n",
       " [1, 444, 2, 1, 190, 3, 1, 445, 446, 2, 8, 45, 191],\n",
       " [182, 10],\n",
       " [182, 10, 14],\n",
       " [182, 10, 14, 192],\n",
       " [182, 10, 14, 192, 24],\n",
       " [182, 10, 14, 192, 24, 447],\n",
       " [182, 10, 14, 192, 24, 447, 448],\n",
       " [182, 10, 14, 192, 24, 447, 448, 449],\n",
       " [182, 10, 14, 192, 24, 447, 448, 449, 26],\n",
       " [182, 10, 14, 192, 24, 447, 448, 449, 26, 1],\n",
       " [182, 10, 14, 192, 24, 447, 448, 449, 26, 1, 193],\n",
       " [182, 10, 14, 192, 24, 447, 448, 449, 26, 1, 193, 2],\n",
       " [182, 10, 14, 192, 24, 447, 448, 449, 26, 1, 193, 2, 450],\n",
       " [3, 451],\n",
       " [3, 451, 8],\n",
       " [3, 451, 8, 194],\n",
       " [3, 451, 8, 194, 452],\n",
       " [3, 451, 8, 194, 452, 3],\n",
       " [3, 451, 8, 194, 452, 3, 195],\n",
       " [3, 451, 8, 194, 452, 3, 195, 196],\n",
       " [3, 451, 8, 194, 452, 3, 195, 196, 2],\n",
       " [453, 12],\n",
       " [453, 12, 454],\n",
       " [453, 12, 454, 72],\n",
       " [453, 12, 454, 72, 197],\n",
       " [453, 12, 454, 72, 197, 455],\n",
       " [453, 12, 454, 72, 197, 455, 3],\n",
       " [453, 12, 454, 72, 197, 455, 3, 198],\n",
       " [453, 12, 454, 72, 197, 455, 3, 198, 41],\n",
       " [453, 12, 454, 72, 197, 455, 3, 198, 41, 197],\n",
       " [456, 17],\n",
       " [456, 17, 25],\n",
       " [456, 17, 25, 42],\n",
       " [456, 17, 25, 42, 457],\n",
       " [456, 17, 25, 42, 457, 24],\n",
       " [456, 17, 25, 42, 457, 24, 458],\n",
       " [456, 17, 25, 42, 457, 24, 458, 26],\n",
       " [456, 17, 25, 42, 457, 24, 458, 26, 1],\n",
       " [456, 17, 25, 42, 457, 24, 458, 26, 1, 459],\n",
       " [456, 17, 25, 42, 457, 24, 458, 26, 1, 459, 460],\n",
       " [28, 121],\n",
       " [28, 121, 5],\n",
       " [28, 121, 5, 121],\n",
       " [28, 121, 5, 121, 7],\n",
       " [28, 121, 5, 121, 7, 108],\n",
       " [28, 121, 5, 121, 7, 108, 122],\n",
       " [28, 121, 5, 121, 7, 108, 122, 461],\n",
       " [28, 121, 5, 121, 7, 108, 122, 461, 123],\n",
       " [28, 121, 5, 121, 7, 108, 122, 461, 123, 2],\n",
       " [28, 121, 5, 121, 7, 108, 122, 461, 123, 2, 8],\n",
       " [28, 121, 5, 121, 7, 108, 122, 461, 123, 2, 8, 462],\n",
       " [28, 121, 5, 121, 7, 108, 122, 461, 123, 2, 8, 462, 2],\n",
       " [28, 121, 5, 121, 7, 108, 122, 461, 123, 2, 8, 462, 2, 8],\n",
       " [463, 5],\n",
       " [463, 5, 464],\n",
       " [463, 5, 464, 12],\n",
       " [463, 5, 464, 12, 1],\n",
       " [463, 5, 464, 12, 1, 65],\n",
       " [463, 5, 464, 12, 1, 65, 2],\n",
       " [463, 5, 464, 12, 1, 65, 2, 1],\n",
       " [463, 5, 464, 12, 1, 65, 2, 1, 465],\n",
       " [463, 5, 464, 12, 1, 65, 2, 1, 465, 466],\n",
       " [463, 5, 464, 12, 1, 65, 2, 1, 465, 466, 2],\n",
       " [463, 5, 464, 12, 1, 65, 2, 1, 465, 466, 2, 8],\n",
       " [463, 5, 464, 12, 1, 65, 2, 1, 465, 466, 2, 8, 198],\n",
       " [463, 5, 464, 12, 1, 65, 2, 1, 465, 466, 2, 8, 198, 41],\n",
       " [2, 1],\n",
       " [2, 1, 199],\n",
       " [2, 1, 199, 467],\n",
       " [2, 1, 199, 467, 2],\n",
       " [2, 1, 199, 467, 2, 1],\n",
       " [2, 1, 199, 467, 2, 1, 468],\n",
       " [2, 1, 199, 467, 2, 1, 468, 469],\n",
       " [2, 1, 199, 467, 2, 1, 468, 469, 22],\n",
       " [2, 1, 199, 467, 2, 1, 468, 469, 22, 470],\n",
       " [2, 1, 199, 467, 2, 1, 468, 469, 22, 470, 3],\n",
       " [471, 2],\n",
       " [471, 2, 1],\n",
       " [471, 2, 1, 472],\n",
       " [471, 2, 1, 472, 17],\n",
       " [471, 2, 1, 472, 17, 10],\n",
       " [471, 2, 1, 472, 17, 10, 25],\n",
       " [471, 2, 1, 472, 17, 10, 25, 473],\n",
       " [471, 2, 1, 472, 17, 10, 25, 473, 50],\n",
       " [471, 2, 1, 472, 17, 10, 25, 473, 50, 474],\n",
       " [471, 2, 1, 472, 17, 10, 25, 473, 50, 474, 3],\n",
       " [475, 27],\n",
       " [475, 27, 1],\n",
       " [475, 27, 1, 200],\n",
       " [475, 27, 1, 200, 476],\n",
       " [475, 27, 1, 200, 476, 2],\n",
       " [475, 27, 1, 200, 476, 2, 477],\n",
       " [475, 27, 1, 200, 476, 2, 477, 478],\n",
       " [475, 27, 1, 200, 476, 2, 477, 478, 201],\n",
       " [475, 27, 1, 200, 476, 2, 477, 478, 201, 479],\n",
       " [475, 27, 1, 200, 476, 2, 477, 478, 201, 479, 2],\n",
       " [8, 480],\n",
       " [8, 480, 481],\n",
       " [8, 480, 481, 17],\n",
       " [8, 480, 481, 17, 7],\n",
       " [8, 480, 481, 17, 7, 482],\n",
       " [8, 480, 481, 17, 7, 482, 483],\n",
       " [8, 480, 481, 17, 7, 482, 483, 16],\n",
       " [8, 480, 481, 17, 7, 482, 483, 16, 40],\n",
       " [8, 480, 481, 17, 7, 482, 483, 16, 40, 1],\n",
       " [8, 480, 481, 17, 7, 482, 483, 16, 40, 1, 484],\n",
       " [8, 480, 481, 17, 7, 482, 483, 16, 40, 1, 484, 2],\n",
       " [1, 485],\n",
       " [1, 485, 486],\n",
       " [1, 485, 486, 7],\n",
       " [1, 485, 486, 7, 202],\n",
       " [1, 485, 486, 7, 202, 70],\n",
       " [1, 485, 486, 7, 202, 70, 2],\n",
       " [1, 485, 486, 7, 202, 70, 2, 18],\n",
       " [1, 485, 486, 7, 202, 70, 2, 18, 487],\n",
       " [1, 485, 486, 7, 202, 70, 2, 18, 487, 124],\n",
       " [1, 485, 486, 7, 202, 70, 2, 18, 487, 124, 3],\n",
       " [1, 485, 486, 7, 202, 70, 2, 18, 487, 124, 3, 488],\n",
       " [37, 489],\n",
       " [37, 489, 14],\n",
       " [37, 489, 14, 73],\n",
       " [37, 489, 14, 73, 1],\n",
       " [37, 489, 14, 73, 1, 490],\n",
       " [37, 489, 14, 73, 1, 490, 2],\n",
       " [37, 489, 14, 73, 1, 490, 2, 491],\n",
       " [37, 489, 14, 73, 1, 490, 2, 491, 492],\n",
       " [37, 489, 14, 73, 1, 490, 2, 491, 492, 14],\n",
       " [37, 489, 14, 73, 1, 490, 2, 491, 492, 14, 493],\n",
       " [37, 489, 14, 73, 1, 490, 2, 491, 492, 14, 493, 28],\n",
       " [37, 489, 14, 73, 1, 490, 2, 491, 492, 14, 493, 28, 4],\n",
       " [494, 5],\n",
       " [494, 5, 4],\n",
       " [494, 5, 4, 495],\n",
       " [494, 5, 4, 495, 27],\n",
       " [494, 5, 4, 495, 27, 7],\n",
       " [494, 5, 4, 495, 27, 7, 25],\n",
       " [494, 5, 4, 495, 27, 7, 25, 125],\n",
       " [494, 5, 4, 495, 27, 7, 25, 125, 496],\n",
       " [494, 5, 4, 495, 27, 7, 25, 125, 496, 5],\n",
       " [494, 5, 4, 495, 27, 7, 25, 125, 496, 5, 497],\n",
       " [494, 5, 4, 495, 27, 7, 25, 125, 496, 5, 497, 126],\n",
       " [494, 5, 4, 495, 27, 7, 25, 125, 496, 5, 497, 126, 498],\n",
       " [18, 203],\n",
       " [18, 203, 499],\n",
       " [18, 203, 499, 29],\n",
       " [18, 203, 499, 29, 500],\n",
       " [18, 203, 499, 29, 500, 187],\n",
       " [18, 203, 499, 29, 500, 187, 188],\n",
       " [18, 203, 499, 29, 500, 187, 188, 24],\n",
       " [18, 203, 499, 29, 500, 187, 188, 24, 7],\n",
       " [18, 203, 499, 29, 500, 187, 188, 24, 7, 501],\n",
       " [18, 203, 499, 29, 500, 187, 188, 24, 7, 501, 1],\n",
       " [18, 203, 499, 29, 500, 187, 188, 24, 7, 501, 1, 204],\n",
       " [18, 203, 499, 29, 500, 187, 188, 24, 7, 501, 1, 204, 502],\n",
       " [205, 17],\n",
       " [205, 17, 127],\n",
       " [205, 17, 127, 106],\n",
       " [205, 17, 127, 106, 21],\n",
       " [205, 17, 127, 106, 21, 503],\n",
       " [205, 17, 127, 106, 21, 503, 12],\n",
       " [205, 17, 127, 106, 21, 503, 12, 18],\n",
       " [205, 17, 127, 106, 21, 503, 12, 18, 112],\n",
       " [205, 17, 127, 106, 21, 503, 12, 18, 112, 16],\n",
       " [205, 17, 127, 106, 21, 503, 12, 18, 112, 16, 18],\n",
       " [205, 17, 127, 106, 21, 503, 12, 18, 112, 16, 18, 504],\n",
       " [205, 17, 127, 106, 21, 503, 12, 18, 112, 16, 18, 504, 3],\n",
       " [16, 1],\n",
       " [16, 1, 206],\n",
       " [16, 1, 206, 505],\n",
       " [16, 1, 206, 505, 2],\n",
       " [16, 1, 206, 505, 2, 1],\n",
       " [16, 1, 206, 505, 2, 1, 193],\n",
       " [16, 1, 206, 505, 2, 1, 193, 12],\n",
       " [16, 1, 206, 505, 2, 1, 193, 12, 506],\n",
       " [16, 1, 206, 505, 2, 1, 193, 12, 506, 7],\n",
       " [16, 1, 206, 505, 2, 1, 193, 12, 506, 7, 14],\n",
       " [16, 1, 206, 505, 2, 1, 193, 12, 506, 7, 14, 507],\n",
       " [16, 1, 206, 505, 2, 1, 193, 12, 506, 7, 14, 507, 16],\n",
       " [16, 1, 206, 505, 2, 1, 193, 12, 506, 7, 14, 507, 16, 4],\n",
       " [191, 508],\n",
       " [191, 508, 5],\n",
       " [191, 508, 5, 58],\n",
       " [191, 508, 5, 58, 20],\n",
       " [191, 508, 5, 58, 20, 86],\n",
       " [191, 508, 5, 58, 20, 86, 3],\n",
       " [191, 508, 5, 58, 20, 86, 3, 5],\n",
       " [191, 508, 5, 58, 20, 86, 3, 5, 74],\n",
       " [191, 508, 5, 58, 20, 86, 3, 5, 74, 59],\n",
       " [191, 508, 5, 58, 20, 86, 3, 5, 74, 59, 10],\n",
       " [191, 508, 5, 58, 20, 86, 3, 5, 74, 59, 10, 14],\n",
       " [191, 508, 5, 58, 20, 86, 3, 5, 74, 59, 10, 14, 509],\n",
       " [191, 508, 5, 58, 20, 86, 3, 5, 74, 59, 10, 14, 509, 8],\n",
       " [195, 196],\n",
       " [195, 196, 8],\n",
       " [195, 196, 8, 207],\n",
       " [195, 196, 8, 207, 54],\n",
       " [195, 196, 8, 207, 54, 510],\n",
       " [195, 196, 8, 207, 54, 510, 511],\n",
       " [195, 196, 8, 207, 54, 510, 511, 3],\n",
       " [195, 196, 8, 207, 54, 510, 511, 3, 512],\n",
       " [195, 196, 8, 207, 54, 510, 511, 3, 512, 24],\n",
       " [195, 196, 8, 207, 54, 510, 511, 3, 512, 24, 7],\n",
       " [87, 41],\n",
       " [87, 41, 7],\n",
       " [87, 41, 7, 128],\n",
       " [87, 41, 7, 128, 8],\n",
       " [87, 41, 7, 128, 8, 513],\n",
       " [87, 41, 7, 128, 8, 513, 514],\n",
       " [87, 41, 7, 128, 8, 513, 514, 515],\n",
       " [87, 41, 7, 128, 8, 513, 514, 515, 516],\n",
       " [87, 41, 7, 128, 8, 513, 514, 515, 516, 517],\n",
       " [87, 41, 7, 128, 8, 513, 514, 515, 516, 517, 12],\n",
       " [87, 41, 7, 128, 8, 513, 514, 515, 516, 517, 12, 4],\n",
       " [87, 41, 7, 128, 8, 513, 514, 515, 516, 517, 12, 4, 206],\n",
       " [87, 41, 7, 128, 8, 513, 514, 515, 516, 517, 12, 4, 206, 518],\n",
       " [208, 1],\n",
       " [208, 1, 519],\n",
       " [208, 1, 519, 10],\n",
       " [208, 1, 519, 10, 14],\n",
       " [208, 1, 519, 10, 14, 520],\n",
       " [208, 1, 519, 10, 14, 520, 1],\n",
       " [208, 1, 519, 10, 14, 520, 1, 209],\n",
       " [208, 1, 519, 10, 14, 520, 1, 209, 521],\n",
       " [208, 1, 519, 10, 14, 520, 1, 209, 521, 522],\n",
       " [208, 1, 519, 10, 14, 520, 1, 209, 521, 522, 16],\n",
       " [208, 1, 519, 10, 14, 520, 1, 209, 521, 522, 16, 8],\n",
       " [523, 524],\n",
       " [523, 524, 34],\n",
       " [523, 524, 34, 8],\n",
       " [523, 524, 34, 8, 210],\n",
       " [523, 524, 34, 8, 210, 3],\n",
       " [523, 524, 34, 8, 210, 3, 8],\n",
       " [523, 524, 34, 8, 210, 3, 8, 211],\n",
       " [523, 524, 34, 8, 210, 3, 8, 211, 525],\n",
       " [523, 524, 34, 8, 210, 3, 8, 211, 525, 526],\n",
       " [523, 524, 34, 8, 210, 3, 8, 211, 525, 526, 66],\n",
       " [523, 524, 34, 8, 210, 3, 8, 211, 525, 526, 66, 5],\n",
       " [523, 524, 34, 8, 210, 3, 8, 211, 525, 526, 66, 5, 29],\n",
       " [523, 524, 34, 8, 210, 3, 8, 211, 525, 526, 66, 5, 29, 30],\n",
       " [202, 8],\n",
       " [202, 8, 119],\n",
       " [202, 8, 119, 527],\n",
       " [202, 8, 119, 527, 3],\n",
       " [202, 8, 119, 527, 3, 528],\n",
       " [202, 8, 119, 527, 3, 528, 8],\n",
       " [202, 8, 119, 527, 3, 528, 8, 529],\n",
       " [202, 8, 119, 527, 3, 528, 8, 529, 3],\n",
       " [202, 8, 119, 527, 3, 528, 8, 529, 3, 212],\n",
       " [202, 8, 119, 527, 3, 528, 8, 529, 3, 212, 213],\n",
       " [202, 8, 119, 527, 3, 528, 8, 529, 3, 212, 213, 530],\n",
       " [202, 8, 119, 527, 3, 528, 8, 529, 3, 212, 213, 530, 45],\n",
       " [531, 10],\n",
       " [531, 10, 14],\n",
       " [531, 10, 14, 22],\n",
       " [531, 10, 14, 22, 214],\n",
       " [531, 10, 14, 22, 214, 86],\n",
       " [531, 10, 14, 22, 214, 86, 10],\n",
       " [531, 10, 14, 22, 214, 86, 10, 25],\n",
       " [531, 10, 14, 22, 214, 86, 10, 25, 532],\n",
       " [531, 10, 14, 22, 214, 86, 10, 25, 532, 72],\n",
       " [531, 10, 14, 22, 214, 86, 10, 25, 532, 72, 2],\n",
       " [531, 10, 14, 22, 214, 86, 10, 25, 532, 72, 2, 8],\n",
       " [531, 10, 14, 22, 214, 86, 10, 25, 532, 72, 2, 8, 190],\n",
       " [531, 10, 14, 22, 214, 86, 10, 25, 532, 72, 2, 8, 190, 533],\n",
       " [534, 3],\n",
       " [534, 3, 14],\n",
       " [534, 3, 14, 535],\n",
       " [534, 3, 14, 535, 34],\n",
       " [534, 3, 14, 535, 34, 1],\n",
       " [534, 3, 14, 535, 34, 1, 536],\n",
       " [534, 3, 14, 535, 34, 1, 536, 2],\n",
       " [534, 3, 14, 535, 34, 1, 536, 2, 122],\n",
       " [534, 3, 14, 535, 34, 1, 536, 2, 122, 537],\n",
       " [534, 3, 14, 535, 34, 1, 536, 2, 122, 537, 538],\n",
       " [534, 3, 14, 535, 34, 1, 536, 2, 122, 537, 538, 7],\n",
       " [534, 3, 14, 535, 34, 1, 536, 2, 122, 537, 538, 7, 539],\n",
       " [534, 3, 14, 535, 34, 1, 536, 2, 122, 537, 538, 7, 539, 1],\n",
       " [534, 3, 14, 535, 34, 1, 536, 2, 122, 537, 538, 7, 539, 1, 215],\n",
       " [3, 14],\n",
       " [3, 14, 216],\n",
       " [3, 14, 216, 41],\n",
       " [3, 14, 216, 41, 5],\n",
       " [3, 14, 216, 41, 5, 1],\n",
       " [3, 14, 216, 41, 5, 1, 217],\n",
       " [3, 14, 216, 41, 5, 1, 217, 17],\n",
       " [3, 14, 216, 41, 5, 1, 217, 17, 25],\n",
       " [3, 14, 216, 41, 5, 1, 217, 17, 25, 540],\n",
       " [3, 14, 216, 41, 5, 1, 217, 17, 25, 540, 42],\n",
       " [3, 14, 216, 41, 5, 1, 217, 17, 25, 540, 42, 12],\n",
       " [3, 14, 216, 41, 5, 1, 217, 17, 25, 540, 42, 12, 129],\n",
       " [3, 14, 216, 41, 5, 1, 217, 17, 25, 540, 42, 12, 129, 18],\n",
       " [3, 14, 216, 41, 5, 1, 217, 17, 25, 540, 42, 12, 129, 18, 45],\n",
       " [8, 212],\n",
       " [8, 212, 14],\n",
       " [8, 212, 14, 23],\n",
       " [8, 212, 14, 23, 541],\n",
       " [8, 212, 14, 23, 541, 11],\n",
       " [8, 212, 14, 23, 541, 11, 167],\n",
       " [8, 212, 14, 23, 541, 11, 167, 14],\n",
       " [8, 212, 14, 23, 541, 11, 167, 14, 38],\n",
       " [8, 212, 14, 23, 541, 11, 167, 14, 38, 10],\n",
       " [8, 212, 14, 23, 541, 11, 167, 14, 38, 10, 14],\n",
       " [8, 212, 14, 23, 541, 11, 167, 14, 38, 10, 14, 542],\n",
       " [8, 212, 14, 23, 541, 11, 167, 14, 38, 10, 14, 542, 7],\n",
       " [8, 212, 14, 23, 541, 11, 167, 14, 38, 10, 14, 542, 7, 130],\n",
       " [5, 58],\n",
       " [5, 58, 29],\n",
       " [5, 58, 29, 16],\n",
       " [5, 58, 29, 16, 131],\n",
       " [5, 58, 29, 16, 131, 4],\n",
       " [5, 58, 29, 16, 131, 4, 218],\n",
       " [5, 58, 29, 16, 131, 4, 218, 543],\n",
       " [5, 58, 29, 16, 131, 4, 218, 543, 38],\n",
       " [5, 58, 29, 16, 131, 4, 218, 543, 38, 16],\n",
       " [5, 58, 29, 16, 131, 4, 218, 543, 38, 16, 4],\n",
       " [5, 58, 29, 16, 131, 4, 218, 543, 38, 16, 4, 544],\n",
       " [5, 58, 29, 16, 131, 4, 218, 543, 38, 16, 4, 544, 545],\n",
       " [5, 58, 29, 16, 131, 4, 218, 543, 38, 16, 4, 544, 545, 10],\n",
       " [5, 58, 29, 16, 131, 4, 218, 543, 38, 16, 4, 544, 545, 10, 546],\n",
       " [29, 5],\n",
       " [29, 5, 44],\n",
       " [29, 5, 44, 88],\n",
       " [29, 5, 44, 88, 219],\n",
       " [29, 5, 44, 88, 219, 132],\n",
       " [29, 5, 44, 88, 219, 132, 8],\n",
       " [29, 5, 44, 88, 219, 132, 8, 65],\n",
       " [29, 5, 44, 88, 219, 132, 8, 65, 2],\n",
       " [29, 5, 44, 88, 219, 132, 8, 65, 2, 547],\n",
       " [29, 5, 44, 88, 219, 132, 8, 65, 2, 547, 3],\n",
       " [29, 5, 44, 88, 219, 132, 8, 65, 2, 547, 3, 548],\n",
       " [29, 5, 44, 88, 219, 132, 8, 65, 2, 547, 3, 548, 4],\n",
       " [549, 65],\n",
       " [549, 65, 3],\n",
       " [549, 65, 3, 4],\n",
       " [549, 65, 3, 4, 550],\n",
       " [549, 65, 3, 4, 550, 12],\n",
       " [549, 65, 3, 4, 550, 12, 1],\n",
       " [549, 65, 3, 4, 550, 12, 1, 551],\n",
       " [549, 65, 3, 4, 550, 12, 1, 551, 133],\n",
       " [549, 65, 3, 4, 550, 12, 1, 551, 133, 10],\n",
       " [549, 65, 3, 4, 550, 12, 1, 551, 133, 10, 552],\n",
       " [549, 65, 3, 4, 550, 12, 1, 551, 133, 10, 552, 134],\n",
       " [549, 65, 3, 4, 550, 12, 1, 551, 133, 10, 552, 134, 1],\n",
       " [549, 65, 3, 4, 550, 12, 1, 551, 133, 10, 552, 134, 1, 553],\n",
       " [3, 87],\n",
       " [3, 87, 29],\n",
       " [3, 87, 29, 135],\n",
       " [3, 87, 29, 135, 12],\n",
       " [3, 87, 29, 135, 12, 8],\n",
       " [3, 87, 29, 135, 12, 8, 199],\n",
       " [3, 87, 29, 135, 12, 8, 199, 554],\n",
       " [3, 87, 29, 135, 12, 8, 199, 554, 555],\n",
       " [556, 557],\n",
       " [556, 557, 9],\n",
       " [556, 557, 9, 6],\n",
       " [556, 557, 9, 6, 10],\n",
       " [556, 557, 9, 6, 10, 89],\n",
       " [556, 557, 9, 6, 10, 89, 46],\n",
       " [556, 557, 9, 6, 10, 89, 46, 130],\n",
       " [556, 557, 9, 6, 10, 89, 46, 130, 90],\n",
       " [556, 557, 9, 6, 10, 89, 46, 130, 90, 13],\n",
       " [556, 557, 9, 6, 10, 89, 46, 130, 90, 13, 9],\n",
       " [556, 557, 9, 6, 10, 89, 46, 130, 90, 13, 9, 19],\n",
       " [556, 557, 9, 6, 10, 89, 46, 130, 90, 13, 9, 19, 558],\n",
       " [73, 559],\n",
       " [73, 559, 3],\n",
       " [73, 559, 3, 4],\n",
       " [73, 559, 3, 4, 220],\n",
       " [73, 559, 3, 4, 220, 560],\n",
       " [73, 559, 3, 4, 220, 560, 136],\n",
       " [73, 559, 3, 4, 220, 560, 136, 7],\n",
       " [73, 559, 3, 4, 220, 560, 136, 7, 128],\n",
       " [73, 559, 3, 4, 220, 560, 136, 7, 128, 9],\n",
       " [73, 559, 3, 4, 220, 560, 136, 7, 128, 9, 6],\n",
       " [561, 6],\n",
       " [561, 6, 7],\n",
       " [561, 6, 7, 221],\n",
       " [562, 7],\n",
       " [562, 7, 222],\n",
       " [562, 7, 222, 19],\n",
       " [562, 7, 222, 19, 563],\n",
       " [562, 7, 222, 19, 563, 4],\n",
       " [562, 7, 222, 19, 563, 4, 70],\n",
       " [562, 7, 222, 19, 563, 4, 70, 116],\n",
       " [562, 7, 222, 19, 563, 4, 70, 116, 91],\n",
       " [562, 7, 222, 19, 563, 4, 70, 116, 91, 4],\n",
       " [562, 7, 222, 19, 563, 4, 70, 116, 91, 4, 564],\n",
       " [562, 7, 222, 19, 563, 4, 70, 116, 91, 4, 564, 116],\n",
       " [562, 7, 222, 19, 563, 4, 70, 116, 91, 4, 564, 116, 7],\n",
       " [565, 90],\n",
       " [565, 90, 3],\n",
       " [565, 90, 3, 12],\n",
       " [565, 90, 3, 12, 126],\n",
       " [565, 90, 3, 12, 126, 86],\n",
       " [565, 90, 3, 12, 126, 86, 7],\n",
       " [565, 90, 3, 12, 126, 86, 7, 223],\n",
       " [565, 90, 3, 12, 126, 86, 7, 223, 9],\n",
       " [565, 90, 3, 12, 126, 86, 7, 223, 9, 224],\n",
       " [565, 90, 3, 12, 126, 86, 7, 223, 9, 224, 23],\n",
       " [565, 90, 3, 12, 126, 86, 7, 223, 9, 224, 23, 225],\n",
       " [565, 90, 3, 12, 126, 86, 7, 223, 9, 224, 23, 225, 29],\n",
       " [13, 9],\n",
       " [13, 9, 566],\n",
       " [13, 9, 566, 5],\n",
       " [13, 9, 566, 5, 137],\n",
       " [13, 9, 566, 5, 137, 57],\n",
       " [13, 9, 566, 5, 137, 57, 567],\n",
       " [13, 9, 566, 5, 137, 57, 567, 6],\n",
       " [138, 59],\n",
       " [138, 59, 35],\n",
       " [138, 59, 35, 9],\n",
       " [138, 59, 35, 9, 74],\n",
       " [138, 59, 35, 9, 74, 6],\n",
       " [46, 58],\n",
       " [46, 58, 11],\n",
       " [46, 58, 11, 7],\n",
       " [46, 58, 11, 7, 139],\n",
       " [46, 58, 11, 7, 139, 11],\n",
       " [46, 58, 11, 7, 139, 11, 59],\n",
       " [46, 58, 11, 7, 139, 11, 59, 35],\n",
       " [46, 58, 11, 7, 139, 11, 59, 35, 7],\n",
       " [46, 58, 11, 7, 139, 11, 59, 35, 7, 74],\n",
       " [46, 58, 11, 7, 139, 11, 59, 35, 7, 74, 13],\n",
       " [46, 58, 11, 7, 139, 11, 59, 35, 7, 74, 13, 9],\n",
       " [46, 58, 11, 7, 139, 11, 59, 35, 7, 74, 13, 9, 19],\n",
       " [46, 58, 11, 7, 139, 11, 59, 35, 7, 74, 13, 9, 19, 42],\n",
       " [46, 58, 11, 7, 139, 11, 59, 35, 7, 74, 13, 9, 19, 42, 568],\n",
       " [569, 75],\n",
       " [569, 75, 570],\n",
       " [569, 75, 570, 183],\n",
       " [569, 75, 570, 183, 3],\n",
       " [569, 75, 570, 183, 3, 13],\n",
       " [569, 75, 570, 183, 3, 13, 9],\n",
       " [569, 75, 570, 183, 3, 13, 9, 19],\n",
       " [569, 75, 570, 183, 3, 13, 9, 19, 4],\n",
       " [569, 75, 570, 183, 3, 13, 9, 19, 4, 114],\n",
       " [569, 75, 570, 183, 3, 13, 9, 19, 4, 114, 571],\n",
       " [569, 75, 570, 183, 3, 13, 9, 19, 4, 114, 571, 3],\n",
       " [569, 75, 570, 183, 3, 13, 9, 19, 4, 114, 571, 3, 572],\n",
       " [573, 574],\n",
       " [573, 574, 6],\n",
       " [226, 575],\n",
       " [226, 575, 20],\n",
       " [226, 575, 20, 6],\n",
       " [226, 575, 20, 6, 31],\n",
       " [226, 575, 20, 6, 31, 7],\n",
       " [226, 575, 20, 6, 31, 7, 140],\n",
       " [226, 575, 20, 6, 31, 7, 140, 15],\n",
       " [226, 575, 20, 6, 31, 7, 140, 15, 227],\n",
       " [226, 575, 20, 6, 31, 7, 140, 15, 227, 141],\n",
       " [226, 575, 20, 6, 31, 7, 140, 15, 227, 141, 9],\n",
       " [226, 575, 20, 6, 31, 7, 140, 15, 227, 141, 9, 56],\n",
       " [226, 575, 20, 6, 31, 7, 140, 15, 227, 141, 9, 56, 576],\n",
       " [226, 575, 20, 6, 31, 7, 140, 15, 227, 141, 9, 56, 576, 19],\n",
       " [42, 577],\n",
       " [42, 577, 25],\n",
       " [42, 577, 25, 9],\n",
       " [42, 577, 25, 9, 578],\n",
       " [42, 577, 25, 9, 578, 4],\n",
       " [42, 577, 25, 9, 578, 4, 579],\n",
       " [42, 577, 25, 9, 578, 4, 579, 580],\n",
       " [42, 577, 25, 9, 578, 4, 579, 580, 581],\n",
       " [42, 577, 25, 9, 578, 4, 579, 580, 581, 11],\n",
       " [42, 577, 25, 9, 578, 4, 579, 580, 581, 11, 15],\n",
       " [42, 577, 25, 9, 578, 4, 579, 580, 581, 11, 15, 582],\n",
       " [42, 577, 25, 9, 578, 4, 579, 580, 581, 11, 15, 582, 13],\n",
       " [42, 577, 25, 9, 578, 4, 579, 580, 581, 11, 15, 582, 13, 7],\n",
       " [42, 577, 25, 9, 578, 4, 579, 580, 581, 11, 15, 582, 13, 7, 25],\n",
       " [42, 577, 25, 9, 578, 4, 579, 580, 581, 11, 15, 582, 13, 7, 25, 4],\n",
       " [583, 584],\n",
       " [583, 584, 73],\n",
       " [583, 584, 73, 585],\n",
       " [583, 584, 73, 585, 3],\n",
       " [583, 584, 73, 585, 3, 228],\n",
       " [583, 584, 73, 585, 3, 228, 185],\n",
       " [583, 584, 73, 585, 3, 228, 185, 12],\n",
       " [583, 584, 73, 585, 3, 228, 185, 12, 4],\n",
       " [583, 584, 73, 585, 3, 228, 185, 12, 4, 586],\n",
       " [583, 584, 73, 585, 3, 228, 185, 12, 4, 586, 587],\n",
       " [583, 584, 73, 585, 3, 228, 185, 12, 4, 586, 587, 38],\n",
       " [583, 584, 73, 585, 3, 228, 185, 12, 4, 586, 587, 38, 24],\n",
       " [583, 584, 73, 585, 3, 228, 185, 12, 4, 586, 587, 38, 24, 7],\n",
       " [19, 588],\n",
       " [19, 588, 18],\n",
       " [19, 588, 18, 589],\n",
       " [19, 588, 18, 589, 7],\n",
       " [19, 588, 18, 589, 7, 590],\n",
       " [19, 588, 18, 589, 7, 590, 229],\n",
       " [19, 588, 18, 589, 7, 590, 229, 59],\n",
       " [19, 588, 18, 589, 7, 590, 229, 59, 9],\n",
       " [19, 588, 18, 589, 7, 590, 229, 59, 9, 139],\n",
       " [19, 588, 18, 589, 7, 590, 229, 59, 9, 139, 11],\n",
       " [19, 588, 18, 589, 7, 590, 229, 59, 9, 139, 11, 24],\n",
       " [19, 588, 18, 589, 7, 590, 229, 59, 9, 139, 11, 24, 5],\n",
       " [19, 588, 18, 589, 7, 590, 229, 59, 9, 139, 11, 24, 5, 591],\n",
       " [592, 105],\n",
       " [592, 105, 15],\n",
       " [592, 105, 15, 593],\n",
       " [592, 105, 15, 593, 3],\n",
       " [592, 105, 15, 593, 3, 18],\n",
       " [592, 105, 15, 593, 3, 18, 594],\n",
       " [592, 105, 15, 593, 3, 18, 594, 55],\n",
       " [592, 105, 15, 593, 3, 18, 594, 55, 595],\n",
       " [592, 105, 15, 593, 3, 18, 594, 55, 595, 109],\n",
       " [592, 105, 15, 593, 3, 18, 594, 55, 595, 109, 596],\n",
       " [592, 105, 15, 593, 3, 18, 594, 55, 595, 109, 596, 38],\n",
       " [592, 105, 15, 593, 3, 18, 594, 55, 595, 109, 596, 38, 49],\n",
       " [86, 7],\n",
       " [86, 7, 597],\n",
       " [86, 7, 597, 5],\n",
       " [86, 7, 597, 5, 58],\n",
       " [86, 7, 597, 5, 58, 59],\n",
       " [86, 7, 597, 5, 58, 59, 9],\n",
       " [86, 7, 597, 5, 58, 59, 9, 214],\n",
       " [86, 7, 597, 5, 58, 59, 9, 214, 11],\n",
       " [86, 7, 597, 5, 58, 59, 9, 214, 11, 72],\n",
       " [86, 7, 597, 5, 58, 59, 9, 214, 11, 72, 6],\n",
       " [10, 598],\n",
       " [10, 598, 5],\n",
       " [10, 598, 5, 69],\n",
       " [10, 598, 5, 69, 3],\n",
       " [10, 598, 5, 69, 3, 599],\n",
       " [10, 598, 5, 69, 3, 599, 8],\n",
       " [10, 598, 5, 69, 3, 599, 8, 230],\n",
       " [10, 598, 5, 69, 3, 599, 8, 230, 600],\n",
       " [10, 598, 5, 69, 3, 599, 8, 230, 600, 211],\n",
       " [10, 598, 5, 69, 3, 599, 8, 230, 600, 211, 601],\n",
       " [92, 15],\n",
       " [92, 15, 602],\n",
       " [92, 15, 602, 231],\n",
       " [92, 15, 602, 231, 6],\n",
       " [92, 15, 602, 231, 6, 31],\n",
       " [92, 15, 602, 231, 6, 31, 10],\n",
       " [92, 15, 602, 231, 6, 31, 10, 226],\n",
       " [92, 15, 602, 231, 6, 31, 10, 226, 67],\n",
       " [92, 15, 602, 231, 6, 31, 10, 226, 67, 225],\n",
       " [92, 15, 602, 231, 6, 31, 10, 226, 67, 225, 29],\n",
       " [92, 15, 602, 231, 6, 31, 10, 226, 67, 225, 29, 13],\n",
       " [92, 15, 602, 231, 6, 31, 10, 226, 67, 225, 29, 13, 73],\n",
       " [92, 15, 602, 231, 6, 31, 10, 226, 67, 225, 29, 13, 73, 1],\n",
       " [92, 15, 602, 231, 6, 31, 10, 226, 67, 225, 29, 13, 73, 1, 603],\n",
       " [2, 36],\n",
       " [2, 36, 604],\n",
       " [2, 36, 604, 605],\n",
       " [2, 36, 604, 605, 91],\n",
       " [2, 36, 604, 605, 91, 142],\n",
       " [2, 36, 604, 605, 91, 142, 1],\n",
       " [2, 36, 604, 605, 91, 142, 1, 606],\n",
       " [2, 36, 604, 605, 91, 142, 1, 606, 607],\n",
       " [2, 36, 604, 605, 91, 142, 1, 606, 607, 11],\n",
       " [2, 36, 604, 605, 91, 142, 1, 606, 607, 11, 1],\n",
       " [2, 36, 604, 605, 91, 142, 1, 606, 607, 11, 1, 608],\n",
       " [2, 36, 604, 605, 91, 142, 1, 606, 607, 11, 1, 608, 15],\n",
       " [609, 26],\n",
       " [609, 26, 143],\n",
       " [609, 26, 143, 158],\n",
       " ...]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8bd754b8-c609-44b7-bc02-02af9c80a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9d3fd5af-c6bc-4139-b788-a96da17e3ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f418a8-ed43-4e14-af97-daf85011b2f5",
   "metadata": {},
   "source": [
    "ZERO PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ea33b751-3277-4ccf-9d90-3c29c6d3e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences= pad_sequences(input_sequences, maxlen= max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4a8e348e-bfcf-41a9-a023-c5155fba5ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   80,  289],\n",
       "       [   0,    0,    0, ...,   80,  289,    1],\n",
       "       [   0,    0,    0, ...,  289,    1,   81],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   88,    3, 1008],\n",
       "       [   0,    0,    0, ...,    3, 1008,    8],\n",
       "       [   0,    0,    0, ..., 1008,    8,   67]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a36ac6fd-c461-4efd-a8c2-a01aa7ede9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= padded_input_sequences[:,:-1]\n",
    "y= padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "82fbc105-bdb9-46d3-ab26-4614664baed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2460, 19)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d7a0a958-e95d-4d36-bfe6-ce9ed5796cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2460,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "039ec8d5-e52d-485b-b450-23b7bf04a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y= to_categorical(y,num_classes= 1009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "165e11aa-9f4b-4efa-8696-23bc1376b45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b10386d4-7801-4380-86b9-59d78661e004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2460, 1009)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "de3d81b0-5880-460e-89e8-1deefe926d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3afdebe1-94e8-416c-a790-25847bc1edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "883da504-19ce-40e7-ad89-efdf3df7c462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABSHIEK RAJ\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Embedding(1009,100,input_length= 20))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(1009, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "91d78c5a-522a-4a86-ab1d-0be439bcc7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "16db520e-7e47-4c33-bb2d-c8350f5bb4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "37cb00c5-136b-4ae4-b966-13dbf9c5ce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,   80],\n",
       "       [   0,    0,    0, ...,    0,   80,  289],\n",
       "       [   0,    0,    0, ...,   80,  289,    1],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    8,   88,    3],\n",
       "       [   0,    0,    0, ...,   88,    3, 1008],\n",
       "       [   0,    0,    0, ...,    3, 1008,    8]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8e653e00-4642-4ef5-b8a2-70e4b7d75ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8c63cdaa-6e04-4f17-9e25-978aa869b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.0396 - loss: 6.5737\n",
      "Epoch 2/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0539 - loss: 5.8496\n",
      "Epoch 3/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0554 - loss: 5.6814\n",
      "Epoch 4/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0680 - loss: 5.4921\n",
      "Epoch 5/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0599 - loss: 5.5135\n",
      "Epoch 6/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0791 - loss: 5.2781\n",
      "Epoch 7/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0762 - loss: 5.1917\n",
      "Epoch 8/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0866 - loss: 5.1032\n",
      "Epoch 9/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0973 - loss: 4.9218\n",
      "Epoch 10/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0929 - loss: 4.8636\n",
      "Epoch 11/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1137 - loss: 4.7041\n",
      "Epoch 12/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1314 - loss: 4.5886\n",
      "Epoch 13/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1349 - loss: 4.4382\n",
      "Epoch 14/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1546 - loss: 4.3437\n",
      "Epoch 15/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1716 - loss: 4.2090\n",
      "Epoch 16/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.1977 - loss: 4.0563\n",
      "Epoch 17/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2158 - loss: 3.8983\n",
      "Epoch 18/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2425 - loss: 3.7619\n",
      "Epoch 19/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2490 - loss: 3.6662\n",
      "Epoch 20/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2654 - loss: 3.5543\n",
      "Epoch 21/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3034 - loss: 3.3775\n",
      "Epoch 22/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3205 - loss: 3.2889\n",
      "Epoch 23/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3375 - loss: 3.1832\n",
      "Epoch 24/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3582 - loss: 3.0471\n",
      "Epoch 25/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3840 - loss: 2.9281\n",
      "Epoch 26/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4182 - loss: 2.7703\n",
      "Epoch 27/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4198 - loss: 2.7429\n",
      "Epoch 28/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4683 - loss: 2.5672\n",
      "Epoch 29/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4928 - loss: 2.4656\n",
      "Epoch 30/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5287 - loss: 2.3496\n",
      "Epoch 31/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5525 - loss: 2.2417\n",
      "Epoch 32/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5746 - loss: 2.1268\n",
      "Epoch 33/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6015 - loss: 2.0153\n",
      "Epoch 34/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6394 - loss: 1.8705\n",
      "Epoch 35/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6614 - loss: 1.7828\n",
      "Epoch 36/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7027 - loss: 1.6738\n",
      "Epoch 37/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6992 - loss: 1.6219\n",
      "Epoch 38/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7203 - loss: 1.5367\n",
      "Epoch 39/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7410 - loss: 1.4525\n",
      "Epoch 40/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7642 - loss: 1.3566\n",
      "Epoch 41/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7780 - loss: 1.3185\n",
      "Epoch 42/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7986 - loss: 1.2298\n",
      "Epoch 43/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8037 - loss: 1.1565\n",
      "Epoch 44/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8107 - loss: 1.1109\n",
      "Epoch 45/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8154 - loss: 1.0627\n",
      "Epoch 46/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8244 - loss: 1.0199\n",
      "Epoch 47/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8402 - loss: 0.9415\n",
      "Epoch 48/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8581 - loss: 0.9004\n",
      "Epoch 49/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8530 - loss: 0.8795\n",
      "Epoch 50/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8828 - loss: 0.7948\n",
      "Epoch 51/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8793 - loss: 0.7615\n",
      "Epoch 52/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8908 - loss: 0.7316\n",
      "Epoch 53/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8869 - loss: 0.7108\n",
      "Epoch 54/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9017 - loss: 0.6640\n",
      "Epoch 55/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9104 - loss: 0.6113\n",
      "Epoch 56/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9254 - loss: 0.5761\n",
      "Epoch 57/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9239 - loss: 0.5563\n",
      "Epoch 58/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9153 - loss: 0.5682\n",
      "Epoch 59/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9202 - loss: 0.5208\n",
      "Epoch 60/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9331 - loss: 0.4681\n",
      "Epoch 61/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9252 - loss: 0.4736\n",
      "Epoch 62/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9339 - loss: 0.4503\n",
      "Epoch 63/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9372 - loss: 0.4093\n",
      "Epoch 64/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9454 - loss: 0.4070\n",
      "Epoch 65/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9525 - loss: 0.3789\n",
      "Epoch 66/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9472 - loss: 0.3614\n",
      "Epoch 67/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9509 - loss: 0.3466\n",
      "Epoch 68/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9567 - loss: 0.3205\n",
      "Epoch 69/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9569 - loss: 0.3067\n",
      "Epoch 70/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9562 - loss: 0.3023\n",
      "Epoch 71/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9586 - loss: 0.2810\n",
      "Epoch 72/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9594 - loss: 0.2711\n",
      "Epoch 73/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9604 - loss: 0.2663\n",
      "Epoch 74/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9619 - loss: 0.2487\n",
      "Epoch 75/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9702 - loss: 0.2292\n",
      "Epoch 76/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9598 - loss: 0.2336\n",
      "Epoch 77/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9694 - loss: 0.2193\n",
      "Epoch 78/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9646 - loss: 0.2235\n",
      "Epoch 79/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9613 - loss: 0.2133\n",
      "Epoch 80/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9631 - loss: 0.1974\n",
      "Epoch 81/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9684 - loss: 0.1865\n",
      "Epoch 82/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9709 - loss: 0.1801\n",
      "Epoch 83/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9656 - loss: 0.1754\n",
      "Epoch 84/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9670 - loss: 0.1643\n",
      "Epoch 85/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9703 - loss: 0.1631\n",
      "Epoch 86/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9634 - loss: 0.1594\n",
      "Epoch 87/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9691 - loss: 0.1479\n",
      "Epoch 88/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9699 - loss: 0.1444\n",
      "Epoch 89/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9617 - loss: 0.1495\n",
      "Epoch 90/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9669 - loss: 0.1359\n",
      "Epoch 91/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9694 - loss: 0.1263\n",
      "Epoch 92/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9657 - loss: 0.1341\n",
      "Epoch 93/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9655 - loss: 0.1320\n",
      "Epoch 94/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9690 - loss: 0.1202\n",
      "Epoch 95/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9621 - loss: 0.1269\n",
      "Epoch 96/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9599 - loss: 0.1307\n",
      "Epoch 97/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9732 - loss: 0.1039\n",
      "Epoch 98/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9697 - loss: 0.1011\n",
      "Epoch 99/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.1010\n",
      "Epoch 100/100\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9679 - loss: 0.1061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x163b6613dd0>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a287ebed-3c6f-4934-a399-cad394004c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  97  15\n",
      "   36 169]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      " what is your name of\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  97  15  36\n",
      "  169   2]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      " what is your name of the\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  97  15  36 169\n",
      "    2   1]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      " what is your name of the maker\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0  97  15  36 169   2\n",
      "    1 757]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      " what is your name of the maker no\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0  97  15  36 169   2   1\n",
      "  757  63]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      " what is your name of the maker no doubt\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0  97  15  36 169   2   1 757\n",
      "   63 180]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      " what is your name of the maker no doubt or\n",
      "[[  0   0   0   0   0   0   0   0   0   0  97  15  36 169   2   1 757  63\n",
      "  180  43]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      " what is your name of the maker no doubt or his\n",
      "[[  0   0   0   0   0   0   0   0   0  97  15  36 169   2   1 757  63 180\n",
      "   43   8]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      " what is your name of the maker no doubt or his monogram\n",
      "[[  0   0   0   0   0   0   0   0  97  15  36 169   2   1 757  63 180  43\n",
      "    8 758]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      " what is your name of the maker no doubt or his monogram rather\n",
      "[[  0   0   0   0   0   0   0  97  15  36 169   2   1 757  63 180  43   8\n",
      "  758 759]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      " what is your name of the maker no doubt or his monogram rather ”\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "text=\" what is your name\"\n",
    "for i in range(10):\n",
    "    #tokenize\n",
    "    token_text= tokenizer.texts_to_sequences([text])[0]\n",
    "    \n",
    "    #padding\n",
    "    padded_token_input=pad_sequences([token_text],maxlen=20,padding='pre')\n",
    "    print(padded_token_input)\n",
    "    \n",
    "    #predict\n",
    "    pos=np.argmax(model.predict(padded_token_input))\n",
    "    \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index== pos:\n",
    "            text= text + \" \"+ word\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af8f684-3696-4ffa-b540-a23e1e70f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
